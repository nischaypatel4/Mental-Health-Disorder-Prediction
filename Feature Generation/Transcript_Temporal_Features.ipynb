{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o91b7j14vexF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd125183-6ee3-4185-907e-4bd305f91ccd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "from shutil import move\n",
        "import whisper\n",
        "from resemblyzer import VoiceEncoder, preprocess_wav\n",
        "from resemblyzer.hparams import sampling_rate\n",
        "import numpy as np\n",
        "import os\n",
        "import librosa\n",
        "from pydub import AudioSegment\n",
        "from sklearn.cluster import KMeans\n",
        "from scipy import stats\n",
        "import pandas as pd\n",
        "\n",
        "# Create output folders\n",
        "os.makedirs(\"all_audio\", exist_ok=True)\n",
        "os.makedirs(\"all_csv\", exist_ok=True)\n",
        "\n",
        "rang = [\n",
        "    673, 677, 680, 684, 692, 695, 697, 702, 703, 707\n",
        "]\n",
        "\n",
        "model = whisper.load_model(\"medium\")\n",
        "\n",
        "for i in range(300,719,1):#rang:\n",
        "  try:\n",
        "    pid = f\"{i}_P\"\n",
        "    archive = f\"{pid}.tar.gz\"\n",
        "    url = f\"https://dcapswoz.ict.usc.edu/wwwedaic/data/{archive}\"\n",
        "\n",
        "    print(f\"\\nðŸ“¥ Downloading: {archive}\")\n",
        "    os.system(f\"wget -q --show-progress {url}\")\n",
        "\n",
        "    print(f\"ðŸ“¦ Extracting audio and CSV from: {archive}\")\n",
        "    os.system(f\"tar --wildcards -xzf {archive} '{pid}/*AUDIO.wav'\")\n",
        "\n",
        "    print(f\"ðŸ§¹ Removing archive: {archive}\")\n",
        "    os.system(f\"rm {archive}\")\n",
        "\n",
        "    # Move the extracted files to organized folders\n",
        "    audio_path = Path(f\"{pid}/{pid.replace('_P','')}_AUDIO.wav\")\n",
        "\n",
        "    if audio_path.exists():\n",
        "        move(str(audio_path), f\"all_audio/{audio_path.name}\")\n",
        "\n",
        "    # Optional: delete the now-empty folder\n",
        "    os.system(f\"rm -rf {pid}\")\n",
        "\n",
        "    print(i)\n",
        "  # Load and preprocess audio\n",
        "    try:\n",
        "      wav_fpath = \"/content/all_audio/\"+str(i)+\"_AUDIO.wav\"\n",
        "      wav, _ = librosa.load(wav_fpath, sr=sampling_rate)\n",
        "    except:\n",
        "      continue\n",
        "    # Create voice embeddings every second\n",
        "    encoder = VoiceEncoder()\n",
        "    embed_frames = encoder.embed_utterance(wav, return_partials=True, rate=1)\n",
        "\n",
        "    # Cluster embeddings\n",
        "    n_speakers = 2  # adjust based on your case\n",
        "    kmeans = KMeans(n_clusters=n_speakers).fit(embed_frames[1])\n",
        "    speaker_labels = kmeans.labels_\n",
        "\n",
        "    # Load Whisper model for transcription\n",
        "    result = model.transcribe(wav_fpath)\n",
        "\n",
        "    # Prepare combined speaker-labeled transcription\n",
        "    transcript = []\n",
        "    for j, segment in enumerate(result['segments']):\n",
        "        start = segment['start']\n",
        "        end = segment['end']\n",
        "        text = segment['text'].strip()\n",
        "\n",
        "        # Approximate speaker label for this time segment\n",
        "        # Use the label of the center of the segment\n",
        "        center_time = int((start + end) / 2)\n",
        "\n",
        "        speaker_id = stats.mode(speaker_labels[center_time-1:center_time+1]) if center_time < len(speaker_labels) else 0\n",
        "\n",
        "        try:\n",
        "          transcript.append({\n",
        "              \"Timestamp\": f\"{start:.2f}â€“{end:.2f}\",\n",
        "              \"Transcript\": text,\n",
        "              \"Speaker\": f\"Speaker {int(speaker_id[0]) + 1}\"\n",
        "          })\n",
        "        except:\n",
        "          pass\n",
        "\n",
        "    # Save to CSV\n",
        "    import pandas as pd\n",
        "    df = pd.DataFrame(transcript)\n",
        "    df.to_csv(\"/content/drive/MyDrive/all_speakers/\"+str(i)+\"_transcript.csv\", index=False)\n",
        "    print(\"Saved as voice_clustered_transcript.csv\")\n",
        "\n",
        "\n",
        "  except:\n",
        "    print(i)\n",
        "    pass\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJcbViYj0z-s",
        "outputId": "8c440b72-55c1-495d-8208-ad558adcf3eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.42G/1.42G [00:27<00:00, 55.5MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“¥ Downloading: 300_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 300_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 300_P.tar.gz\n",
            "300\n",
            "Loaded the voice encoder model on cpu in 0.03 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "300\n",
            "\n",
            "ðŸ“¥ Downloading: 301_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 301_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 301_P.tar.gz\n",
            "301\n",
            "\n",
            "ðŸ“¥ Downloading: 302_P.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3-3883333130.py:53: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  wav, _ = librosa.load(wav_fpath, sr=sampling_rate)\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“¦ Extracting audio and CSV from: 302_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 302_P.tar.gz\n",
            "302\n",
            "Loaded the voice encoder model on cpu in 0.03 seconds.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "drive_audio = \"/content/all_audio\"\n",
        "# Zip audio files\n",
        "audio_zip_path = \"/content//all_audio.zip\"\n",
        "with zipfile.ZipFile(audio_zip_path, 'w') as audio_zip:\n",
        "    for file in os.listdir(drive_audio):\n",
        "        file_path = os.path.join(drive_audio, file)\n",
        "        audio_zip.write(file_path, arcname=file)\n",
        "\n",
        "print(\"âœ… Zipping complete!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "iF4taaec0XvY",
        "outputId": "bca29d36-19d7-4e6d-b375-c8eb77a6e46a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'os' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1-2522397896.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0maudio_zip_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content//all_audio.zip\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_zip_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0maudio_zip\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrive_audio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrive_audio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0maudio_zip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marcname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai-whisper\n",
        "!pip install pydub\n",
        "!pip install google-generativeai\n",
        "!pip install tensorflow\n",
        "!pip install opensmile soundfile"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MsFn_SBcIHag",
        "outputId": "d0069b72-172b-47d6-ec12-43de20ae4100"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai-whisper\n",
            "  Downloading openai-whisper-20240930.tar.gz (800 kB)\n",
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/800.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m \u001b[32m788.5/800.5 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m800.5/800.5 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (2.0.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (4.67.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (10.7.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (0.9.0)\n",
            "Requirement already satisfied: triton>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (3.2.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->openai-whisper) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper) (2.32.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->openai-whisper)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->openai-whisper)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->openai-whisper) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2025.6.15)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->openai-whisper) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m57.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m941.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20240930-py3-none-any.whl size=803404 sha256=28acf479830b0d65f25d2d83a2f4ba751542c4597e79f166f4f1bd058d0cf00e\n",
            "  Stored in directory: /root/.cache/pip/wheels/2f/f2/ce/6eb23db4091d026238ce76703bd66da60b969d70bcc81d5d3a\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, openai-whisper\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 openai-whisper-20240930\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (0.25.1)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.5)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.25.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.172.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (5.29.5)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.11.7)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.14.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.4.1)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.73.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.6.15)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.14.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.73.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.6.15)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Collecting opensmile\n",
            "  Downloading opensmile-2.5.1-py3-none-manylinux_2_17_x86_64.whl.metadata (15 kB)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.11/dist-packages (0.13.1)\n",
            "Collecting audobject>=0.6.1 (from opensmile)\n",
            "  Downloading audobject-0.7.12-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting audinterface>=0.7.0 (from opensmile)\n",
            "  Downloading audinterface-1.3.1-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile) (1.17.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from soundfile) (2.0.2)\n",
            "Collecting audeer>=2.1.1 (from audinterface>=0.7.0->opensmile)\n",
            "  Downloading audeer-2.2.2-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting audformat<2.0.0,>=1.0.1 (from audinterface>=0.7.0->opensmile)\n",
            "  Downloading audformat-1.3.2-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting audiofile>=1.3.0 (from audinterface>=0.7.0->opensmile)\n",
            "  Downloading audiofile-1.5.1-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting audmath>=1.4.1 (from audinterface>=0.7.0->opensmile)\n",
            "  Downloading audmath-1.4.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting audresample<2.0.0,>=1.1.0 (from audinterface>=0.7.0->opensmile)\n",
            "  Downloading audresample-1.3.4-py3-none-manylinux_2_17_x86_64.whl.metadata (4.4 kB)\n",
            "Collecting asttokens>=2.0.0 (from audobject>=0.6.1->opensmile)\n",
            "  Downloading asttokens-3.0.0-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from audobject>=0.6.1->opensmile) (8.7.0)\n",
            "Collecting oyaml (from audobject>=0.6.1->opensmile)\n",
            "  Downloading oyaml-1.0-py2.py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from audobject>=0.6.1->opensmile) (24.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile) (2.22)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from audeer>=2.1.1->audinterface>=0.7.0->opensmile) (4.67.1)\n",
            "Collecting iso639-lang (from audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile)\n",
            "  Downloading iso639_lang-2.6.0-py3-none-any.whl.metadata (8.8 kB)\n",
            "Collecting iso3166 (from audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile)\n",
            "  Downloading iso3166-2.1.1-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: pandas>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile) (2.2.2)\n",
            "Requirement already satisfied: pyarrow>=10.0.1 in /usr/local/lib/python3.11/dist-packages (from audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile) (18.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.4.1 in /usr/local/lib/python3.11/dist-packages (from audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile) (6.0.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata>=4.8.0->audobject>=0.6.1->opensmile) (3.23.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1.0->audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1.0->audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1.0->audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=2.1.0->audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile) (1.17.0)\n",
            "Downloading opensmile-2.5.1-py3-none-manylinux_2_17_x86_64.whl (996 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m996.0/996.0 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading audinterface-1.3.1-py3-none-any.whl (81 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m81.4/81.4 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading audobject-0.7.12-py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m42.9/42.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading asttokens-3.0.0-py3-none-any.whl (26 kB)\n",
            "Downloading audeer-2.2.2-py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m41.8/41.8 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading audformat-1.3.2-py3-none-any.whl (158 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m158.2/158.2 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading audiofile-1.5.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading audmath-1.4.2-py3-none-any.whl (23 kB)\n",
            "Downloading audresample-1.3.4-py3-none-manylinux_2_17_x86_64.whl (138 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m138.4/138.4 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading oyaml-1.0-py2.py3-none-any.whl (3.0 kB)\n",
            "Downloading iso3166-2.1.1-py3-none-any.whl (9.8 kB)\n",
            "Downloading iso639_lang-2.6.0-py3-none-any.whl (324 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m324.8/324.8 kB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: oyaml, iso639-lang, iso3166, audresample, audmath, audeer, asttokens, audobject, audiofile, audformat, audinterface, opensmile\n",
            "Successfully installed asttokens-3.0.0 audeer-2.2.2 audformat-1.3.2 audinterface-1.3.1 audiofile-1.5.1 audmath-1.4.2 audobject-0.7.12 audresample-1.3.4 iso3166-2.1.1 iso639-lang-2.6.0 opensmile-2.5.1 oyaml-1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai-whisper\n",
        "!pip install pydub\n",
        "!pip install google-generativeai\n",
        "!pip install tensorflow\n",
        "!pip install opensmile soundfile\n",
        "!pip install pyannote.audio\n",
        "!pip install resemblyzer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3KrEdC1td4OB",
        "outputId": "2c4283cf-6af0-4e10-e410-4ce6bddea8ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai-whisper\n",
            "  Downloading openai-whisper-20240930.tar.gz (800 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m800.5/800.5 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (2.0.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (4.67.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (10.7.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (0.9.0)\n",
            "Requirement already satisfied: triton>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (3.2.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->openai-whisper) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper) (2.32.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->openai-whisper)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->openai-whisper)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->openai-whisper) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2025.6.15)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->openai-whisper) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m97.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m82.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m72.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20240930-py3-none-any.whl size=803404 sha256=58160be42e1a0575fd2dc9c0d5cf9d5bf58a8bd6b7aad6f513241205847e8894\n",
            "  Stored in directory: /root/.cache/pip/wheels/2f/f2/ce/6eb23db4091d026238ce76703bd66da60b969d70bcc81d5d3a\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, openai-whisper\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 openai-whisper-20240930\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (0.25.1)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.5)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.25.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.172.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (5.29.5)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.11.7)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.14.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.4.1)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.73.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.6.15)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.14.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.73.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.6.15)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Collecting opensmile\n",
            "  Downloading opensmile-2.5.1-py3-none-manylinux_2_17_x86_64.whl.metadata (15 kB)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.11/dist-packages (0.13.1)\n",
            "Collecting audobject>=0.6.1 (from opensmile)\n",
            "  Downloading audobject-0.7.12-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting audinterface>=0.7.0 (from opensmile)\n",
            "  Downloading audinterface-1.3.1-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile) (1.17.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from soundfile) (2.0.2)\n",
            "Collecting audeer>=2.1.1 (from audinterface>=0.7.0->opensmile)\n",
            "  Downloading audeer-2.2.2-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting audformat<2.0.0,>=1.0.1 (from audinterface>=0.7.0->opensmile)\n",
            "  Downloading audformat-1.3.2-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting audiofile>=1.3.0 (from audinterface>=0.7.0->opensmile)\n",
            "  Downloading audiofile-1.5.1-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting audmath>=1.4.1 (from audinterface>=0.7.0->opensmile)\n",
            "  Downloading audmath-1.4.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting audresample<2.0.0,>=1.1.0 (from audinterface>=0.7.0->opensmile)\n",
            "  Downloading audresample-1.3.4-py3-none-manylinux_2_17_x86_64.whl.metadata (4.4 kB)\n",
            "Collecting asttokens>=2.0.0 (from audobject>=0.6.1->opensmile)\n",
            "  Downloading asttokens-3.0.0-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from audobject>=0.6.1->opensmile) (8.7.0)\n",
            "Collecting oyaml (from audobject>=0.6.1->opensmile)\n",
            "  Downloading oyaml-1.0-py2.py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from audobject>=0.6.1->opensmile) (24.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile) (2.22)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from audeer>=2.1.1->audinterface>=0.7.0->opensmile) (4.67.1)\n",
            "Collecting iso639-lang (from audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile)\n",
            "  Downloading iso639_lang-2.6.0-py3-none-any.whl.metadata (8.8 kB)\n",
            "Collecting iso3166 (from audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile)\n",
            "  Downloading iso3166-2.1.1-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: pandas>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile) (2.2.2)\n",
            "Requirement already satisfied: pyarrow>=10.0.1 in /usr/local/lib/python3.11/dist-packages (from audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile) (18.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.4.1 in /usr/local/lib/python3.11/dist-packages (from audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile) (6.0.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata>=4.8.0->audobject>=0.6.1->opensmile) (3.23.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1.0->audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1.0->audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1.0->audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=2.1.0->audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile) (1.17.0)\n",
            "Downloading opensmile-2.5.1-py3-none-manylinux_2_17_x86_64.whl (996 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m996.0/996.0 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading audinterface-1.3.1-py3-none-any.whl (81 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m81.4/81.4 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading audobject-0.7.12-py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m42.9/42.9 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading asttokens-3.0.0-py3-none-any.whl (26 kB)\n",
            "Downloading audeer-2.2.2-py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m41.8/41.8 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading audformat-1.3.2-py3-none-any.whl (158 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m158.2/158.2 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading audiofile-1.5.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading audmath-1.4.2-py3-none-any.whl (23 kB)\n",
            "Downloading audresample-1.3.4-py3-none-manylinux_2_17_x86_64.whl (138 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m138.4/138.4 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading oyaml-1.0-py2.py3-none-any.whl (3.0 kB)\n",
            "Downloading iso3166-2.1.1-py3-none-any.whl (9.8 kB)\n",
            "Downloading iso639_lang-2.6.0-py3-none-any.whl (324 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m324.8/324.8 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: oyaml, iso639-lang, iso3166, audresample, audmath, audeer, asttokens, audobject, audiofile, audformat, audinterface, opensmile\n",
            "Successfully installed asttokens-3.0.0 audeer-2.2.2 audformat-1.3.2 audinterface-1.3.1 audiofile-1.5.1 audmath-1.4.2 audobject-0.7.12 audresample-1.3.4 iso3166-2.1.1 iso639-lang-2.6.0 opensmile-2.5.1 oyaml-1.0\n",
            "Collecting pyannote.audio\n",
            "  Downloading pyannote.audio-3.3.2-py2.py3-none-any.whl.metadata (11 kB)\n",
            "Collecting asteroid-filterbanks>=0.4 (from pyannote.audio)\n",
            "  Downloading asteroid_filterbanks-0.4.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: einops>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pyannote.audio) (0.8.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.13.0 in /usr/local/lib/python3.11/dist-packages (from pyannote.audio) (0.33.0)\n",
            "Collecting lightning>=2.0.1 (from pyannote.audio)\n",
            "  Downloading lightning-2.5.1.post0-py3-none-any.whl.metadata (39 kB)\n",
            "Requirement already satisfied: omegaconf<3.0,>=2.1 in /usr/local/lib/python3.11/dist-packages (from pyannote.audio) (2.3.0)\n",
            "Collecting pyannote.core>=5.0.0 (from pyannote.audio)\n",
            "  Downloading pyannote.core-5.0.0-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting pyannote.database>=5.0.1 (from pyannote.audio)\n",
            "  Downloading pyannote.database-5.1.3-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting pyannote.metrics>=3.2 (from pyannote.audio)\n",
            "  Downloading pyannote.metrics-3.2.1-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting pyannote.pipeline>=3.0.1 (from pyannote.audio)\n",
            "  Downloading pyannote.pipeline-3.0.1-py3-none-any.whl.metadata (897 bytes)\n",
            "Collecting pytorch-metric-learning>=2.1.0 (from pyannote.audio)\n",
            "  Downloading pytorch_metric_learning-2.8.1-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: rich>=12.0.0 in /usr/local/lib/python3.11/dist-packages (from pyannote.audio) (13.9.4)\n",
            "Collecting semver>=3.0.0 (from pyannote.audio)\n",
            "  Downloading semver-3.0.4-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from pyannote.audio) (0.13.1)\n",
            "Collecting speechbrain>=1.0.0 (from pyannote.audio)\n",
            "  Downloading speechbrain-1.0.3-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting tensorboardX>=2.6 (from pyannote.audio)\n",
            "  Downloading tensorboardx-2.6.4-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pyannote.audio) (2.6.0+cu124)\n",
            "Collecting torch-audiomentations>=0.11.0 (from pyannote.audio)\n",
            "  Downloading torch_audiomentations-0.12.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: torchaudio>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from pyannote.audio) (2.6.0+cu124)\n",
            "Collecting torchmetrics>=0.11.0 (from pyannote.audio)\n",
            "  Downloading torchmetrics-1.7.3-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from asteroid-filterbanks>=0.4->pyannote.audio) (2.0.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from asteroid-filterbanks>=0.4->pyannote.audio) (4.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13.0->pyannote.audio) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13.0->pyannote.audio) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13.0->pyannote.audio) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13.0->pyannote.audio) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13.0->pyannote.audio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13.0->pyannote.audio) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13.0->pyannote.audio) (1.1.3)\n",
            "Collecting lightning-utilities<2.0,>=0.10.0 (from lightning>=2.0.1->pyannote.audio)\n",
            "  Downloading lightning_utilities-0.14.3-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting pytorch-lightning (from lightning>=2.0.1->pyannote.audio)\n",
            "  Downloading pytorch_lightning-2.5.1.post0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from omegaconf<3.0,>=2.1->pyannote.audio) (4.9.3)\n",
            "Requirement already satisfied: sortedcontainers>=2.0.4 in /usr/local/lib/python3.11/dist-packages (from pyannote.core>=5.0.0->pyannote.audio) (2.4.0)\n",
            "Requirement already satisfied: scipy>=1.1 in /usr/local/lib/python3.11/dist-packages (from pyannote.core>=5.0.0->pyannote.audio) (1.15.3)\n",
            "Requirement already satisfied: pandas>=0.19 in /usr/local/lib/python3.11/dist-packages (from pyannote.database>=5.0.1->pyannote.audio) (2.2.2)\n",
            "Requirement already satisfied: typer>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from pyannote.database>=5.0.1->pyannote.audio) (0.16.0)\n",
            "Requirement already satisfied: scikit-learn>=0.17.1 in /usr/local/lib/python3.11/dist-packages (from pyannote.metrics>=3.2->pyannote.audio) (1.6.1)\n",
            "Collecting docopt>=0.6.2 (from pyannote.metrics>=3.2->pyannote.audio)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.11/dist-packages (from pyannote.metrics>=3.2->pyannote.audio) (0.9.0)\n",
            "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pyannote.metrics>=3.2->pyannote.audio) (3.10.0)\n",
            "Requirement already satisfied: sympy>=1.1 in /usr/local/lib/python3.11/dist-packages (from pyannote.metrics>=3.2->pyannote.audio) (1.13.1)\n",
            "Collecting optuna>=3.1 (from pyannote.pipeline>=3.0.1->pyannote.audio)\n",
            "  Downloading optuna-4.4.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=12.0.0->pyannote.audio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=12.0.0->pyannote.audio) (2.19.1)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->pyannote.audio) (1.17.1)\n",
            "Collecting hyperpyyaml (from speechbrain>=1.0.0->pyannote.audio)\n",
            "  Downloading HyperPyYAML-1.2.2-py3-none-any.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from speechbrain>=1.0.0->pyannote.audio) (1.5.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from speechbrain>=1.0.0->pyannote.audio) (0.2.0)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.11/dist-packages (from tensorboardX>=2.6->pyannote.audio) (5.29.5)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (3.2.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.1->pyannote.metrics>=3.2->pyannote.audio) (1.3.0)\n",
            "Collecting julius<0.3,>=0.2.3 (from torch-audiomentations>=0.11.0->pyannote.audio)\n",
            "  Downloading julius-0.2.7.tar.gz (59 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m59.6/59.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torch-pitch-shift>=1.2.2 (from torch-audiomentations>=0.11.0->pyannote.audio)\n",
            "  Downloading torch_pitch_shift-1.2.5-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->pyannote.audio) (2.22)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (3.11.15)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities<2.0,>=0.10.0->lightning>=2.0.1->pyannote.audio) (75.2.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=12.0.0->pyannote.audio) (0.1.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (2.9.0.post0)\n",
            "Collecting alembic>=1.5.0 (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio)\n",
            "  Downloading alembic-1.16.2-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting colorlog (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio) (2.0.41)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.19->pyannote.database>=5.0.1->pyannote.audio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.19->pyannote.database>=5.0.1->pyannote.audio) (2025.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.17.1->pyannote.metrics>=3.2->pyannote.audio) (3.6.0)\n",
            "Collecting primePy>=1.3 (from torch-pitch-shift>=1.2.2->torch-audiomentations>=0.11.0->pyannote.audio)\n",
            "  Downloading primePy-1.3-py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.12.1->pyannote.database>=5.0.1->pyannote.audio) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.12.1->pyannote.database>=5.0.1->pyannote.audio) (1.5.4)\n",
            "Collecting ruamel.yaml>=0.17.28 (from hyperpyyaml->speechbrain>=1.0.0->pyannote.audio)\n",
            "  Downloading ruamel.yaml-0.18.14-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->pyannote.audio) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.13.0->pyannote.audio) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.13.0->pyannote.audio) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.13.0->pyannote.audio) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.13.0->pyannote.audio) (2025.6.15)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (1.20.1)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio) (1.1.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (1.17.0)\n",
            "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain>=1.0.0->pyannote.audio)\n",
            "  Downloading ruamel.yaml.clib-0.2.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio) (3.2.3)\n",
            "Downloading pyannote.audio-3.3.2-py2.py3-none-any.whl (898 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m898.7/898.7 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading asteroid_filterbanks-0.4.0-py3-none-any.whl (29 kB)\n",
            "Downloading lightning-2.5.1.post0-py3-none-any.whl (819 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m819.0/819.0 kB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyannote.core-5.0.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m58.5/58.5 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyannote.database-5.1.3-py3-none-any.whl (48 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m48.1/48.1 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyannote.metrics-3.2.1-py3-none-any.whl (51 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m51.4/51.4 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyannote.pipeline-3.0.1-py3-none-any.whl (31 kB)\n",
            "Downloading pytorch_metric_learning-2.8.1-py3-none-any.whl (125 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m125.9/125.9 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading semver-3.0.4-py3-none-any.whl (17 kB)\n",
            "Downloading speechbrain-1.0.3-py3-none-any.whl (864 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m864.1/864.1 kB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboardx-2.6.4-py3-none-any.whl (87 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch_audiomentations-0.12.0-py3-none-any.whl (48 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchmetrics-1.7.3-py3-none-any.whl (962 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m962.6/962.6 kB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.14.3-py3-none-any.whl (28 kB)\n",
            "Downloading optuna-4.4.0-py3-none-any.whl (395 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m395.9/395.9 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch_pitch_shift-1.2.5-py3-none-any.whl (5.0 kB)\n",
            "Downloading HyperPyYAML-1.2.2-py3-none-any.whl (16 kB)\n",
            "Downloading pytorch_lightning-2.5.1.post0-py3-none-any.whl (823 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m823.1/823.1 kB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.16.2-py3-none-any.whl (242 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m242.7/242.7 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading primePy-1.3-py3-none-any.whl (4.0 kB)\n",
            "Downloading ruamel.yaml-0.18.14-py3-none-any.whl (118 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m118.6/118.6 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading ruamel.yaml.clib-0.2.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (739 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m739.1/739.1 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: docopt, julius\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=3ec0f1d7da00045b44b73c4684deadae6f0994d841d013c23c01b0117bbd3d06\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/b0/8c/4b75c4116c31f83c8f9f047231251e13cc74481cca4a78a9ce\n",
            "  Building wheel for julius (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for julius: filename=julius-0.2.7-py3-none-any.whl size=21870 sha256=09c503cb5b28a416b62df8b55724d3b970461e44a184df0895631dcc86d7c210\n",
            "  Stored in directory: /root/.cache/pip/wheels/16/15/d4/edd724cefe78050a6ba3344b8b0c6672db829a799dbb9f81ff\n",
            "Successfully built docopt julius\n",
            "Installing collected packages: primePy, docopt, tensorboardX, semver, ruamel.yaml.clib, lightning-utilities, colorlog, ruamel.yaml, pyannote.core, alembic, optuna, hyperpyyaml, torchmetrics, pytorch-metric-learning, pyannote.database, julius, asteroid-filterbanks, torch-pitch-shift, speechbrain, pytorch-lightning, pyannote.pipeline, pyannote.metrics, torch-audiomentations, lightning, pyannote.audio\n",
            "Successfully installed alembic-1.16.2 asteroid-filterbanks-0.4.0 colorlog-6.9.0 docopt-0.6.2 hyperpyyaml-1.2.2 julius-0.2.7 lightning-2.5.1.post0 lightning-utilities-0.14.3 optuna-4.4.0 primePy-1.3 pyannote.audio-3.3.2 pyannote.core-5.0.0 pyannote.database-5.1.3 pyannote.metrics-3.2.1 pyannote.pipeline-3.0.1 pytorch-lightning-2.5.1.post0 pytorch-metric-learning-2.8.1 ruamel.yaml-0.18.14 ruamel.yaml.clib-0.2.12 semver-3.0.4 speechbrain-1.0.3 tensorboardX-2.6.4 torch-audiomentations-0.12.0 torch-pitch-shift-1.2.5 torchmetrics-1.7.3\n",
            "Collecting resemblyzer\n",
            "  Downloading Resemblyzer-0.1.4-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: librosa>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from resemblyzer) (0.11.0)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.11/dist-packages (from resemblyzer) (2.0.2)\n",
            "Collecting webrtcvad>=2.0.10 (from resemblyzer)\n",
            "  Downloading webrtcvad-2.0.10.tar.gz (66 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m66.2/66.2 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from resemblyzer) (2.6.0+cu124)\n",
            "Requirement already satisfied: scipy>=1.2.1 in /usr/local/lib/python3.11/dist-packages (from resemblyzer) (1.15.3)\n",
            "Collecting typing (from resemblyzer)\n",
            "  Downloading typing-3.7.4.3.tar.gz (78 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.9.1->resemblyzer) (3.0.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.9.1->resemblyzer) (0.60.0)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.9.1->resemblyzer) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.9.1->resemblyzer) (1.5.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.9.1->resemblyzer) (4.4.2)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.9.1->resemblyzer) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.9.1->resemblyzer) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.9.1->resemblyzer) (0.5.0.post1)\n",
            "Requirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.9.1->resemblyzer) (4.14.0)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.9.1->resemblyzer) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.9.1->resemblyzer) (1.1.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.1->resemblyzer) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.1->resemblyzer) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.1->resemblyzer) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.1->resemblyzer) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.1->resemblyzer) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.1->resemblyzer) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.1->resemblyzer) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.1->resemblyzer) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.1->resemblyzer) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.1->resemblyzer) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.1->resemblyzer) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.1->resemblyzer) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.1->resemblyzer) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.1->resemblyzer) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.1->resemblyzer) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.1->resemblyzer) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.1->resemblyzer) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.1->resemblyzer) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.1->resemblyzer) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.0.1->resemblyzer) (1.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from lazy_loader>=0.1->librosa>=0.9.1->resemblyzer) (24.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa>=0.9.1->resemblyzer) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa>=0.9.1->resemblyzer) (4.3.8)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa>=0.9.1->resemblyzer) (2.32.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1.0->librosa>=0.9.1->resemblyzer) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa>=0.9.1->resemblyzer) (1.17.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.0.1->resemblyzer) (3.0.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa>=0.9.1->resemblyzer) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa>=0.9.1->resemblyzer) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa>=0.9.1->resemblyzer) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa>=0.9.1->resemblyzer) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa>=0.9.1->resemblyzer) (2025.6.15)\n",
            "Downloading Resemblyzer-0.1.4-py3-none-any.whl (15.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m71.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: webrtcvad, typing\n",
            "  Building wheel for webrtcvad (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for webrtcvad: filename=webrtcvad-2.0.10-cp311-cp311-linux_x86_64.whl size=73507 sha256=99bb6fd66d3cac26becad4b2ece036283030012ceac4dad5a73cf6af6af81207\n",
            "  Stored in directory: /root/.cache/pip/wheels/94/65/3f/292d0b656be33d1c801831201c74b5f68f41a2ae465ff2ee2f\n",
            "  Building wheel for typing (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for typing: filename=typing-3.7.4.3-py3-none-any.whl size=26304 sha256=d8183a26872ac43b27528bbe3f4797e2a61be0ca6cbd8026f1a15a84f9168255\n",
            "  Stored in directory: /root/.cache/pip/wheels/9d/67/2f/53e3ef32ec48d11d7d60245255e2d71e908201d20c880c08ee\n",
            "Successfully built webrtcvad typing\n",
            "Installing collected packages: webrtcvad, typing, resemblyzer\n",
            "Successfully installed resemblyzer-0.1.4 typing-3.7.4.3 webrtcvad-2.0.10\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "typing"
                ]
              },
              "id": "69fd4542e4c44a5cb4c4d70b57148ed4"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "from resemblyzer import VoiceEncoder, preprocess_wav\n",
        "from resemblyzer.hparams import sampling_rate\n",
        "import numpy as np\n",
        "import os\n",
        "import librosa\n",
        "from pydub import AudioSegment\n",
        "from sklearn.cluster import KMeans\n",
        "from scipy import stats\n",
        "import pandas as pd\n",
        "\n",
        "# model = whisper.load_model(\"medium\")\n",
        "\n",
        "for i in range(300,719,1):\n",
        "  print(i)\n",
        "# Load and preprocess audio\n",
        "  try:\n",
        "    wav_fpath = \"/content/all_audio/\"+str(i)+\"_AUDIO.wav\"\n",
        "    wav, _ = librosa.load(wav_fpath, sr=sampling_rate)\n",
        "  except:\n",
        "    continue\n",
        "  # Create voice embeddings every second\n",
        "  encoder = VoiceEncoder()\n",
        "  embed_frames = encoder.embed_utterance(wav, return_partials=True, rate=1)\n",
        "\n",
        "  # Cluster embeddings\n",
        "  n_speakers = 2  # adjust based on your case\n",
        "  kmeans = KMeans(n_clusters=n_speakers).fit(embed_frames[1])\n",
        "  speaker_labels = kmeans.labels_\n",
        "\n",
        "  # Load Whisper model for transcription\n",
        "  result = model.transcribe(wav_fpath)\n",
        "\n",
        "  # try:\n",
        "  #   result = pd.read_csv(\"/content/transcripts/\"+str(i)+\"_transcript.csv\")\n",
        "  # except:\n",
        "  #   continue\n",
        "\n",
        "  # Prepare combined speaker-labeled transcription\n",
        "  transcript = []\n",
        "  for j, segment in enumerate(result['segments']):\n",
        "      start = segment['start']\n",
        "      end = segment['end']\n",
        "      text = segment['text'].strip()\n",
        "\n",
        "  # for j in range(result.shape[0]):\n",
        "  #     start = result['start'].iloc[j]\n",
        "  #     end = result['end'].iloc[j]\n",
        "  #     text = result['text'].iloc[j].strip()\n",
        "\n",
        "      # Approximate speaker label for this time segment\n",
        "      # Use the label of the center of the segment\n",
        "      center_time = int((start + end) / 2)\n",
        "\n",
        "      speaker_id = stats.mode(speaker_labels[center_time-1:center_time+1]) if center_time < len(speaker_labels) else 0\n",
        "\n",
        "      try:\n",
        "        transcript.append({\n",
        "            \"Timestamp\": f\"{start:.2f}â€“{end:.2f}\",\n",
        "            \"Transcript\": text,\n",
        "            \"Speaker\": f\"Speaker {int(speaker_id[0]) + 1}\"\n",
        "        })\n",
        "      except:\n",
        "        pass\n",
        "\n",
        "  # Save to CSV\n",
        "  import pandas as pd\n",
        "  df = pd.DataFrame(transcript)\n",
        "  df.to_csv(\"/content/all_speakers/\"+str(i)+\"_transcript.csv\", index=False)\n",
        "  print(\"Saved as voice_clustered_transcript.csv\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EiD6of8Id-ee",
        "outputId": "78d23697-ce8f-4a2f-9cea-2fa3332c10c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "300\n",
            "Loaded the voice encoder model on cuda in 0.02 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3-3128896435.py:55: SmallSampleWarning: One or more sample arguments is too small; all returned values will be NaN. See documentation for sample size requirements.\n",
            "  speaker_id = stats.mode(speaker_labels[center_time-1:center_time+1]) if center_time < len(speaker_labels) else 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved as voice_clustered_transcript.csv\n",
            "301\n",
            "Loaded the voice encoder model on cuda in 0.01 seconds.\n",
            "Saved as voice_clustered_transcript.csv\n",
            "302\n",
            "Loaded the voice encoder model on cuda in 0.01 seconds.\n",
            "Saved as voice_clustered_transcript.csv\n",
            "303\n",
            "Loaded the voice encoder model on cuda in 0.02 seconds.\n",
            "Saved as voice_clustered_transcript.csv\n",
            "304\n",
            "Loaded the voice encoder model on cuda in 0.02 seconds.\n",
            "Saved as voice_clustered_transcript.csv\n",
            "305\n",
            "Loaded the voice encoder model on cuda in 0.01 seconds.\n",
            "Saved as voice_clustered_transcript.csv\n",
            "306\n",
            "Loaded the voice encoder model on cuda in 0.02 seconds.\n",
            "Saved as voice_clustered_transcript.csv\n",
            "307\n",
            "Loaded the voice encoder model on cuda in 0.01 seconds.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# import shutil\n",
        "\n",
        "# dir_path = '/content/all_speakers'\n",
        "\n",
        "# if os.path.exists(dir_path):\n",
        "#     shutil.rmtree(dir_path)\n",
        "#     print(f\"Deleted: {dir_path}\")\n",
        "# else:\n",
        "#     print(f\"Directory not found: {dir_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "xj-pKJRH3Lq5",
        "outputId": "3cc14aef-4730-4341-aafb-b36ea1c13b17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "[Errno 125] Operation canceled: '/content/drive/MyDrive'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-5-4218193840.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmtree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Deleted: {dir_path}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/shutil.py\u001b[0m in \u001b[0;36mrmtree\u001b[0;34m(path, ignore_errors, onerror, dir_fd)\u001b[0m\n\u001b[1;32m    761\u001b[0m                     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdir_fd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdir_fd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 763\u001b[0;31m                     \u001b[0monerror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    764\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/shutil.py\u001b[0m in \u001b[0;36mrmtree\u001b[0;34m(path, ignore_errors, onerror, dir_fd)\u001b[0m\n\u001b[1;32m    759\u001b[0m                 \u001b[0mfd_closed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m                     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdir_fd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdir_fd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m                     \u001b[0monerror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: [Errno 125] Operation canceled: '/content/drive/MyDrive'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "drive_audio = \"/content/all_speakers\"\n",
        "# Zip audio files\n",
        "audio_zip_path = \"/content/all_transcripts.zip\"\n",
        "with zipfile.ZipFile(audio_zip_path, 'w') as audio_zip:\n",
        "    for file in os.listdir(drive_audio):\n",
        "        file_path = os.path.join(drive_audio, file)\n",
        "        audio_zip.write(file_path, arcname=file)\n",
        "\n",
        "print(\"âœ… Zipping complete!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7L4tMKr_etl-",
        "outputId": "4037795b-f4c2-4d05-8c99-783c25d26996"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Zipping complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "from pydub import AudioSegment\n",
        "import google.generativeai as genai\n",
        "from datetime import timedelta\n",
        "import os, glob, zipfile\n",
        "import pandas as pd\n",
        "import opensmile"
      ],
      "metadata": {
        "id": "fIYAUStFI4bu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_whisper = whisper.load_model(\"small\")\n",
        "\n",
        "def transcribe_audio(audio_path):\n",
        "    result = model_whisper.transcribe(audio_path)\n",
        "    return result[\"segments\"]  # Each has 'text', 'start', 'end'\n",
        "\n",
        "def clean_transcription(segment_text):\n",
        "    prompt = (\n",
        "        \"The following transcription has possible mistakes and repeated phrases. \"\n",
        "        \"Please correct transcription errors and remove duplicate content:\\n\\n\"\n",
        "        f\"\\\"{segment_text}\\\"\\n\\n\"\n",
        "        \"Return only the cleaned text.\"\n",
        "    )\n",
        "    response = model.generate_content(prompt)\n",
        "    return response.text.strip()\n",
        "\n",
        "def extract_segment(audio_path, start_sec, end_sec, output_path):\n",
        "    audio = AudioSegment.from_wav(audio_path)\n",
        "    segment = audio[start_sec * 1000 : end_sec * 1000]  # milliseconds\n",
        "    segment.export(output_path, format=\"wav\")"
      ],
      "metadata": {
        "id": "6Md14A8jJA9i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import os\n",
        "\n",
        "def process_audio_pipeline(audio_path, output_csv_path=\"segments.csv\"):\n",
        "    segments = transcribe_audio(audio_path)\n",
        "\n",
        "    # Open CSV file for writing\n",
        "    with open(output_csv_path, mode='w', newline='', encoding='utf-8') as csvfile:\n",
        "        writer = csv.DictWriter(csvfile, fieldnames=['text', 'start', 'end'])\n",
        "        writer.writeheader()\n",
        "\n",
        "        for i, seg in enumerate(segments):\n",
        "            writer.writerow({\n",
        "                'text': seg['text'],\n",
        "                'start': seg['start'],\n",
        "                'end': seg['end']\n",
        "            })\n",
        "\n",
        "    print(f\"\\n CSV saved at: {output_csv_path}\")"
      ],
      "metadata": {
        "id": "ThTvpK-mJBvi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def batch_process_audio(folder_path, output_folder=\"/content/drive/MyDrive/CGS_Audio_FacialData/transcripts\"):\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    for i in range(300, 719):  # 719 because range is exclusive on the upper end\n",
        "        file_name = f\"all_audio/{i}_AUDIO.wav\"\n",
        "        file_path = os.path.join(folder_path, file_name)\n",
        "\n",
        "        if os.path.exists(file_path):\n",
        "            output_csv = os.path.join(output_folder, f\"{i}_transcript.csv\")\n",
        "            try:\n",
        "                print(f\"Processing {file_name}...\")\n",
        "                process_audio_pipeline(file_path, output_csv_path=output_csv)\n",
        "            except Exception as e:\n",
        "                print(f\" Error processing {file_name}: {e}\")\n",
        "        else:\n",
        "            print(f\" File not found: {file_name}\")\n",
        "\n",
        "# ðŸ”§ Usage\n",
        "batch_process_audio(\"/content/\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RlmTMjpUJFQg",
        "outputId": "350bc7ad-e14d-4f0c-dfda-6ae526ac5f24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " File not found: all_audio/300_AUDIO.wav\n",
            " File not found: all_audio/301_AUDIO.wav\n",
            " File not found: all_audio/302_AUDIO.wav\n",
            " File not found: all_audio/303_AUDIO.wav\n",
            " File not found: all_audio/304_AUDIO.wav\n",
            " File not found: all_audio/305_AUDIO.wav\n",
            " File not found: all_audio/306_AUDIO.wav\n",
            " File not found: all_audio/307_AUDIO.wav\n",
            " File not found: all_audio/308_AUDIO.wav\n",
            " File not found: all_audio/309_AUDIO.wav\n",
            " File not found: all_audio/310_AUDIO.wav\n",
            " File not found: all_audio/311_AUDIO.wav\n",
            " File not found: all_audio/312_AUDIO.wav\n",
            " File not found: all_audio/313_AUDIO.wav\n",
            " File not found: all_audio/314_AUDIO.wav\n",
            " File not found: all_audio/315_AUDIO.wav\n",
            " File not found: all_audio/316_AUDIO.wav\n",
            " File not found: all_audio/317_AUDIO.wav\n",
            " File not found: all_audio/318_AUDIO.wav\n",
            " File not found: all_audio/319_AUDIO.wav\n",
            " File not found: all_audio/320_AUDIO.wav\n",
            " File not found: all_audio/321_AUDIO.wav\n",
            " File not found: all_audio/322_AUDIO.wav\n",
            " File not found: all_audio/323_AUDIO.wav\n",
            " File not found: all_audio/324_AUDIO.wav\n",
            " File not found: all_audio/325_AUDIO.wav\n",
            " File not found: all_audio/326_AUDIO.wav\n",
            " File not found: all_audio/327_AUDIO.wav\n",
            " File not found: all_audio/328_AUDIO.wav\n",
            " File not found: all_audio/329_AUDIO.wav\n",
            " File not found: all_audio/330_AUDIO.wav\n",
            " File not found: all_audio/331_AUDIO.wav\n",
            " File not found: all_audio/332_AUDIO.wav\n",
            " File not found: all_audio/333_AUDIO.wav\n",
            " File not found: all_audio/334_AUDIO.wav\n",
            " File not found: all_audio/335_AUDIO.wav\n",
            " File not found: all_audio/336_AUDIO.wav\n",
            " File not found: all_audio/337_AUDIO.wav\n",
            " File not found: all_audio/338_AUDIO.wav\n",
            " File not found: all_audio/339_AUDIO.wav\n",
            " File not found: all_audio/340_AUDIO.wav\n",
            " File not found: all_audio/341_AUDIO.wav\n",
            " File not found: all_audio/342_AUDIO.wav\n",
            " File not found: all_audio/343_AUDIO.wav\n",
            " File not found: all_audio/344_AUDIO.wav\n",
            " File not found: all_audio/345_AUDIO.wav\n",
            " File not found: all_audio/346_AUDIO.wav\n",
            " File not found: all_audio/347_AUDIO.wav\n",
            " File not found: all_audio/348_AUDIO.wav\n",
            " File not found: all_audio/349_AUDIO.wav\n",
            " File not found: all_audio/350_AUDIO.wav\n",
            " File not found: all_audio/351_AUDIO.wav\n",
            " File not found: all_audio/352_AUDIO.wav\n",
            " File not found: all_audio/353_AUDIO.wav\n",
            " File not found: all_audio/354_AUDIO.wav\n",
            " File not found: all_audio/355_AUDIO.wav\n",
            " File not found: all_audio/356_AUDIO.wav\n",
            " File not found: all_audio/357_AUDIO.wav\n",
            " File not found: all_audio/358_AUDIO.wav\n",
            " File not found: all_audio/359_AUDIO.wav\n",
            " File not found: all_audio/360_AUDIO.wav\n",
            " File not found: all_audio/361_AUDIO.wav\n",
            " File not found: all_audio/362_AUDIO.wav\n",
            " File not found: all_audio/363_AUDIO.wav\n",
            " File not found: all_audio/364_AUDIO.wav\n",
            " File not found: all_audio/365_AUDIO.wav\n",
            " File not found: all_audio/366_AUDIO.wav\n",
            " File not found: all_audio/367_AUDIO.wav\n",
            " File not found: all_audio/368_AUDIO.wav\n",
            " File not found: all_audio/369_AUDIO.wav\n",
            " File not found: all_audio/370_AUDIO.wav\n",
            " File not found: all_audio/371_AUDIO.wav\n",
            " File not found: all_audio/372_AUDIO.wav\n",
            " File not found: all_audio/373_AUDIO.wav\n",
            " File not found: all_audio/374_AUDIO.wav\n",
            " File not found: all_audio/375_AUDIO.wav\n",
            " File not found: all_audio/376_AUDIO.wav\n",
            " File not found: all_audio/377_AUDIO.wav\n",
            " File not found: all_audio/378_AUDIO.wav\n",
            " File not found: all_audio/379_AUDIO.wav\n",
            " File not found: all_audio/380_AUDIO.wav\n",
            " File not found: all_audio/381_AUDIO.wav\n",
            " File not found: all_audio/382_AUDIO.wav\n",
            " File not found: all_audio/383_AUDIO.wav\n",
            " File not found: all_audio/384_AUDIO.wav\n",
            " File not found: all_audio/385_AUDIO.wav\n",
            " File not found: all_audio/386_AUDIO.wav\n",
            " File not found: all_audio/387_AUDIO.wav\n",
            " File not found: all_audio/388_AUDIO.wav\n",
            " File not found: all_audio/389_AUDIO.wav\n",
            " File not found: all_audio/390_AUDIO.wav\n",
            " File not found: all_audio/391_AUDIO.wav\n",
            " File not found: all_audio/392_AUDIO.wav\n",
            " File not found: all_audio/393_AUDIO.wav\n",
            " File not found: all_audio/394_AUDIO.wav\n",
            " File not found: all_audio/395_AUDIO.wav\n",
            " File not found: all_audio/396_AUDIO.wav\n",
            " File not found: all_audio/397_AUDIO.wav\n",
            " File not found: all_audio/398_AUDIO.wav\n",
            " File not found: all_audio/399_AUDIO.wav\n",
            " File not found: all_audio/400_AUDIO.wav\n",
            " File not found: all_audio/401_AUDIO.wav\n",
            " File not found: all_audio/402_AUDIO.wav\n",
            " File not found: all_audio/403_AUDIO.wav\n",
            " File not found: all_audio/404_AUDIO.wav\n",
            " File not found: all_audio/405_AUDIO.wav\n",
            " File not found: all_audio/406_AUDIO.wav\n",
            " File not found: all_audio/407_AUDIO.wav\n",
            " File not found: all_audio/408_AUDIO.wav\n",
            " File not found: all_audio/409_AUDIO.wav\n",
            " File not found: all_audio/410_AUDIO.wav\n",
            " File not found: all_audio/411_AUDIO.wav\n",
            " File not found: all_audio/412_AUDIO.wav\n",
            " File not found: all_audio/413_AUDIO.wav\n",
            " File not found: all_audio/414_AUDIO.wav\n",
            " File not found: all_audio/415_AUDIO.wav\n",
            " File not found: all_audio/416_AUDIO.wav\n",
            " File not found: all_audio/417_AUDIO.wav\n",
            " File not found: all_audio/418_AUDIO.wav\n",
            " File not found: all_audio/419_AUDIO.wav\n",
            " File not found: all_audio/420_AUDIO.wav\n",
            " File not found: all_audio/421_AUDIO.wav\n",
            " File not found: all_audio/422_AUDIO.wav\n",
            " File not found: all_audio/423_AUDIO.wav\n",
            " File not found: all_audio/424_AUDIO.wav\n",
            " File not found: all_audio/425_AUDIO.wav\n",
            " File not found: all_audio/426_AUDIO.wav\n",
            " File not found: all_audio/427_AUDIO.wav\n",
            " File not found: all_audio/428_AUDIO.wav\n",
            " File not found: all_audio/429_AUDIO.wav\n",
            " File not found: all_audio/430_AUDIO.wav\n",
            " File not found: all_audio/431_AUDIO.wav\n",
            " File not found: all_audio/432_AUDIO.wav\n",
            " File not found: all_audio/433_AUDIO.wav\n",
            " File not found: all_audio/434_AUDIO.wav\n",
            " File not found: all_audio/435_AUDIO.wav\n",
            " File not found: all_audio/436_AUDIO.wav\n",
            " File not found: all_audio/437_AUDIO.wav\n",
            " File not found: all_audio/438_AUDIO.wav\n",
            " File not found: all_audio/439_AUDIO.wav\n",
            " File not found: all_audio/440_AUDIO.wav\n",
            " File not found: all_audio/441_AUDIO.wav\n",
            " File not found: all_audio/442_AUDIO.wav\n",
            " File not found: all_audio/443_AUDIO.wav\n",
            " File not found: all_audio/444_AUDIO.wav\n",
            " File not found: all_audio/445_AUDIO.wav\n",
            " File not found: all_audio/446_AUDIO.wav\n",
            " File not found: all_audio/447_AUDIO.wav\n",
            " File not found: all_audio/448_AUDIO.wav\n",
            " File not found: all_audio/449_AUDIO.wav\n",
            " File not found: all_audio/450_AUDIO.wav\n",
            " File not found: all_audio/451_AUDIO.wav\n",
            " File not found: all_audio/452_AUDIO.wav\n",
            " File not found: all_audio/453_AUDIO.wav\n",
            " File not found: all_audio/454_AUDIO.wav\n",
            " File not found: all_audio/455_AUDIO.wav\n",
            " File not found: all_audio/456_AUDIO.wav\n",
            " File not found: all_audio/457_AUDIO.wav\n",
            " File not found: all_audio/458_AUDIO.wav\n",
            " File not found: all_audio/459_AUDIO.wav\n",
            " File not found: all_audio/460_AUDIO.wav\n",
            " File not found: all_audio/461_AUDIO.wav\n",
            " File not found: all_audio/462_AUDIO.wav\n",
            " File not found: all_audio/463_AUDIO.wav\n",
            " File not found: all_audio/464_AUDIO.wav\n",
            " File not found: all_audio/465_AUDIO.wav\n",
            " File not found: all_audio/466_AUDIO.wav\n",
            " File not found: all_audio/467_AUDIO.wav\n",
            " File not found: all_audio/468_AUDIO.wav\n",
            " File not found: all_audio/469_AUDIO.wav\n",
            " File not found: all_audio/470_AUDIO.wav\n",
            " File not found: all_audio/471_AUDIO.wav\n",
            " File not found: all_audio/472_AUDIO.wav\n",
            " File not found: all_audio/473_AUDIO.wav\n",
            " File not found: all_audio/474_AUDIO.wav\n",
            " File not found: all_audio/475_AUDIO.wav\n",
            " File not found: all_audio/476_AUDIO.wav\n",
            " File not found: all_audio/477_AUDIO.wav\n",
            " File not found: all_audio/478_AUDIO.wav\n",
            " File not found: all_audio/479_AUDIO.wav\n",
            " File not found: all_audio/480_AUDIO.wav\n",
            " File not found: all_audio/481_AUDIO.wav\n",
            " File not found: all_audio/482_AUDIO.wav\n",
            " File not found: all_audio/483_AUDIO.wav\n",
            " File not found: all_audio/484_AUDIO.wav\n",
            " File not found: all_audio/485_AUDIO.wav\n",
            " File not found: all_audio/486_AUDIO.wav\n",
            " File not found: all_audio/487_AUDIO.wav\n",
            " File not found: all_audio/488_AUDIO.wav\n",
            " File not found: all_audio/489_AUDIO.wav\n",
            " File not found: all_audio/490_AUDIO.wav\n",
            " File not found: all_audio/491_AUDIO.wav\n",
            " File not found: all_audio/492_AUDIO.wav\n",
            " File not found: all_audio/493_AUDIO.wav\n",
            " File not found: all_audio/494_AUDIO.wav\n",
            " File not found: all_audio/495_AUDIO.wav\n",
            " File not found: all_audio/496_AUDIO.wav\n",
            " File not found: all_audio/497_AUDIO.wav\n",
            " File not found: all_audio/498_AUDIO.wav\n",
            " File not found: all_audio/499_AUDIO.wav\n",
            " File not found: all_audio/500_AUDIO.wav\n",
            " File not found: all_audio/501_AUDIO.wav\n",
            " File not found: all_audio/502_AUDIO.wav\n",
            " File not found: all_audio/503_AUDIO.wav\n",
            " File not found: all_audio/504_AUDIO.wav\n",
            " File not found: all_audio/505_AUDIO.wav\n",
            " File not found: all_audio/506_AUDIO.wav\n",
            " File not found: all_audio/507_AUDIO.wav\n",
            " File not found: all_audio/508_AUDIO.wav\n",
            " File not found: all_audio/509_AUDIO.wav\n",
            " File not found: all_audio/510_AUDIO.wav\n",
            " File not found: all_audio/511_AUDIO.wav\n",
            " File not found: all_audio/512_AUDIO.wav\n",
            " File not found: all_audio/513_AUDIO.wav\n",
            " File not found: all_audio/514_AUDIO.wav\n",
            " File not found: all_audio/515_AUDIO.wav\n",
            " File not found: all_audio/516_AUDIO.wav\n",
            " File not found: all_audio/517_AUDIO.wav\n",
            " File not found: all_audio/518_AUDIO.wav\n",
            " File not found: all_audio/519_AUDIO.wav\n",
            " File not found: all_audio/520_AUDIO.wav\n",
            " File not found: all_audio/521_AUDIO.wav\n",
            " File not found: all_audio/522_AUDIO.wav\n",
            " File not found: all_audio/523_AUDIO.wav\n",
            " File not found: all_audio/524_AUDIO.wav\n",
            " File not found: all_audio/525_AUDIO.wav\n",
            " File not found: all_audio/526_AUDIO.wav\n",
            " File not found: all_audio/527_AUDIO.wav\n",
            " File not found: all_audio/528_AUDIO.wav\n",
            " File not found: all_audio/529_AUDIO.wav\n",
            " File not found: all_audio/530_AUDIO.wav\n",
            " File not found: all_audio/531_AUDIO.wav\n",
            " File not found: all_audio/532_AUDIO.wav\n",
            " File not found: all_audio/533_AUDIO.wav\n",
            " File not found: all_audio/534_AUDIO.wav\n",
            " File not found: all_audio/535_AUDIO.wav\n",
            " File not found: all_audio/536_AUDIO.wav\n",
            " File not found: all_audio/537_AUDIO.wav\n",
            " File not found: all_audio/538_AUDIO.wav\n",
            " File not found: all_audio/539_AUDIO.wav\n",
            " File not found: all_audio/540_AUDIO.wav\n",
            " File not found: all_audio/541_AUDIO.wav\n",
            " File not found: all_audio/542_AUDIO.wav\n",
            " File not found: all_audio/543_AUDIO.wav\n",
            " File not found: all_audio/544_AUDIO.wav\n",
            " File not found: all_audio/545_AUDIO.wav\n",
            " File not found: all_audio/546_AUDIO.wav\n",
            " File not found: all_audio/547_AUDIO.wav\n",
            " File not found: all_audio/548_AUDIO.wav\n",
            " File not found: all_audio/549_AUDIO.wav\n",
            " File not found: all_audio/550_AUDIO.wav\n",
            " File not found: all_audio/551_AUDIO.wav\n",
            " File not found: all_audio/552_AUDIO.wav\n",
            " File not found: all_audio/553_AUDIO.wav\n",
            " File not found: all_audio/554_AUDIO.wav\n",
            " File not found: all_audio/555_AUDIO.wav\n",
            " File not found: all_audio/556_AUDIO.wav\n",
            " File not found: all_audio/557_AUDIO.wav\n",
            " File not found: all_audio/558_AUDIO.wav\n",
            " File not found: all_audio/559_AUDIO.wav\n",
            " File not found: all_audio/560_AUDIO.wav\n",
            " File not found: all_audio/561_AUDIO.wav\n",
            " File not found: all_audio/562_AUDIO.wav\n",
            " File not found: all_audio/563_AUDIO.wav\n",
            " File not found: all_audio/564_AUDIO.wav\n",
            " File not found: all_audio/565_AUDIO.wav\n",
            " File not found: all_audio/566_AUDIO.wav\n",
            " File not found: all_audio/567_AUDIO.wav\n",
            " File not found: all_audio/568_AUDIO.wav\n",
            " File not found: all_audio/569_AUDIO.wav\n",
            " File not found: all_audio/570_AUDIO.wav\n",
            " File not found: all_audio/571_AUDIO.wav\n",
            " File not found: all_audio/572_AUDIO.wav\n",
            " File not found: all_audio/573_AUDIO.wav\n",
            " File not found: all_audio/574_AUDIO.wav\n",
            " File not found: all_audio/575_AUDIO.wav\n",
            " File not found: all_audio/576_AUDIO.wav\n",
            " File not found: all_audio/577_AUDIO.wav\n",
            " File not found: all_audio/578_AUDIO.wav\n",
            " File not found: all_audio/579_AUDIO.wav\n",
            " File not found: all_audio/580_AUDIO.wav\n",
            " File not found: all_audio/581_AUDIO.wav\n",
            " File not found: all_audio/582_AUDIO.wav\n",
            " File not found: all_audio/583_AUDIO.wav\n",
            " File not found: all_audio/584_AUDIO.wav\n",
            " File not found: all_audio/585_AUDIO.wav\n",
            " File not found: all_audio/586_AUDIO.wav\n",
            " File not found: all_audio/587_AUDIO.wav\n",
            " File not found: all_audio/588_AUDIO.wav\n",
            " File not found: all_audio/589_AUDIO.wav\n",
            " File not found: all_audio/590_AUDIO.wav\n",
            " File not found: all_audio/591_AUDIO.wav\n",
            " File not found: all_audio/592_AUDIO.wav\n",
            " File not found: all_audio/593_AUDIO.wav\n",
            " File not found: all_audio/594_AUDIO.wav\n",
            " File not found: all_audio/595_AUDIO.wav\n",
            " File not found: all_audio/596_AUDIO.wav\n",
            " File not found: all_audio/597_AUDIO.wav\n",
            " File not found: all_audio/598_AUDIO.wav\n",
            " File not found: all_audio/599_AUDIO.wav\n",
            " File not found: all_audio/600_AUDIO.wav\n",
            " File not found: all_audio/601_AUDIO.wav\n",
            " File not found: all_audio/602_AUDIO.wav\n",
            " File not found: all_audio/603_AUDIO.wav\n",
            " File not found: all_audio/604_AUDIO.wav\n",
            " File not found: all_audio/605_AUDIO.wav\n",
            " File not found: all_audio/606_AUDIO.wav\n",
            " File not found: all_audio/607_AUDIO.wav\n",
            " File not found: all_audio/608_AUDIO.wav\n",
            " File not found: all_audio/609_AUDIO.wav\n",
            " File not found: all_audio/610_AUDIO.wav\n",
            " File not found: all_audio/611_AUDIO.wav\n",
            " File not found: all_audio/612_AUDIO.wav\n",
            " File not found: all_audio/613_AUDIO.wav\n",
            " File not found: all_audio/614_AUDIO.wav\n",
            " File not found: all_audio/615_AUDIO.wav\n",
            " File not found: all_audio/616_AUDIO.wav\n",
            " File not found: all_audio/617_AUDIO.wav\n",
            " File not found: all_audio/618_AUDIO.wav\n",
            " File not found: all_audio/619_AUDIO.wav\n",
            " File not found: all_audio/620_AUDIO.wav\n",
            " File not found: all_audio/621_AUDIO.wav\n",
            " File not found: all_audio/622_AUDIO.wav\n",
            " File not found: all_audio/623_AUDIO.wav\n",
            " File not found: all_audio/624_AUDIO.wav\n",
            " File not found: all_audio/625_AUDIO.wav\n",
            " File not found: all_audio/626_AUDIO.wav\n",
            " File not found: all_audio/627_AUDIO.wav\n",
            " File not found: all_audio/628_AUDIO.wav\n",
            " File not found: all_audio/629_AUDIO.wav\n",
            " File not found: all_audio/630_AUDIO.wav\n",
            " File not found: all_audio/631_AUDIO.wav\n",
            " File not found: all_audio/632_AUDIO.wav\n",
            " File not found: all_audio/633_AUDIO.wav\n",
            " File not found: all_audio/634_AUDIO.wav\n",
            " File not found: all_audio/635_AUDIO.wav\n",
            " File not found: all_audio/636_AUDIO.wav\n",
            " File not found: all_audio/637_AUDIO.wav\n",
            " File not found: all_audio/638_AUDIO.wav\n",
            " File not found: all_audio/639_AUDIO.wav\n",
            " File not found: all_audio/640_AUDIO.wav\n",
            " File not found: all_audio/641_AUDIO.wav\n",
            " File not found: all_audio/642_AUDIO.wav\n",
            " File not found: all_audio/643_AUDIO.wav\n",
            " File not found: all_audio/644_AUDIO.wav\n",
            " File not found: all_audio/645_AUDIO.wav\n",
            " File not found: all_audio/646_AUDIO.wav\n",
            " File not found: all_audio/647_AUDIO.wav\n",
            " File not found: all_audio/648_AUDIO.wav\n",
            " File not found: all_audio/649_AUDIO.wav\n",
            " File not found: all_audio/650_AUDIO.wav\n",
            " File not found: all_audio/651_AUDIO.wav\n",
            " File not found: all_audio/652_AUDIO.wav\n",
            " File not found: all_audio/653_AUDIO.wav\n",
            " File not found: all_audio/654_AUDIO.wav\n",
            " File not found: all_audio/655_AUDIO.wav\n",
            " File not found: all_audio/656_AUDIO.wav\n",
            " File not found: all_audio/657_AUDIO.wav\n",
            " File not found: all_audio/658_AUDIO.wav\n",
            " File not found: all_audio/659_AUDIO.wav\n",
            " File not found: all_audio/660_AUDIO.wav\n",
            " File not found: all_audio/661_AUDIO.wav\n",
            " File not found: all_audio/662_AUDIO.wav\n",
            " File not found: all_audio/663_AUDIO.wav\n",
            " File not found: all_audio/664_AUDIO.wav\n",
            " File not found: all_audio/665_AUDIO.wav\n",
            " File not found: all_audio/666_AUDIO.wav\n",
            " File not found: all_audio/667_AUDIO.wav\n",
            " File not found: all_audio/668_AUDIO.wav\n",
            " File not found: all_audio/669_AUDIO.wav\n",
            " File not found: all_audio/670_AUDIO.wav\n",
            " File not found: all_audio/671_AUDIO.wav\n",
            " File not found: all_audio/672_AUDIO.wav\n",
            "Processing all_audio/673_AUDIO.wav...\n",
            "\n",
            " CSV saved at: /content/drive/MyDrive/CGS_Audio_FacialData/transcripts/673_transcript.csv\n",
            " File not found: all_audio/674_AUDIO.wav\n",
            " File not found: all_audio/675_AUDIO.wav\n",
            " File not found: all_audio/676_AUDIO.wav\n",
            "Processing all_audio/677_AUDIO.wav...\n",
            "\n",
            " CSV saved at: /content/drive/MyDrive/CGS_Audio_FacialData/transcripts/677_transcript.csv\n",
            " File not found: all_audio/678_AUDIO.wav\n",
            " File not found: all_audio/679_AUDIO.wav\n",
            "Processing all_audio/680_AUDIO.wav...\n",
            "\n",
            " CSV saved at: /content/drive/MyDrive/CGS_Audio_FacialData/transcripts/680_transcript.csv\n",
            " File not found: all_audio/681_AUDIO.wav\n",
            " File not found: all_audio/682_AUDIO.wav\n",
            " File not found: all_audio/683_AUDIO.wav\n",
            "Processing all_audio/684_AUDIO.wav...\n",
            "\n",
            " CSV saved at: /content/drive/MyDrive/CGS_Audio_FacialData/transcripts/684_transcript.csv\n",
            " File not found: all_audio/685_AUDIO.wav\n",
            " File not found: all_audio/686_AUDIO.wav\n",
            " File not found: all_audio/687_AUDIO.wav\n",
            " File not found: all_audio/688_AUDIO.wav\n",
            " File not found: all_audio/689_AUDIO.wav\n",
            " File not found: all_audio/690_AUDIO.wav\n",
            " File not found: all_audio/691_AUDIO.wav\n",
            "Processing all_audio/692_AUDIO.wav...\n",
            "\n",
            " CSV saved at: /content/drive/MyDrive/CGS_Audio_FacialData/transcripts/692_transcript.csv\n",
            " File not found: all_audio/693_AUDIO.wav\n",
            " File not found: all_audio/694_AUDIO.wav\n",
            "Processing all_audio/695_AUDIO.wav...\n",
            "\n",
            " CSV saved at: /content/drive/MyDrive/CGS_Audio_FacialData/transcripts/695_transcript.csv\n",
            " File not found: all_audio/696_AUDIO.wav\n",
            "Processing all_audio/697_AUDIO.wav...\n",
            "\n",
            " CSV saved at: /content/drive/MyDrive/CGS_Audio_FacialData/transcripts/697_transcript.csv\n",
            " File not found: all_audio/698_AUDIO.wav\n",
            " File not found: all_audio/699_AUDIO.wav\n",
            " File not found: all_audio/700_AUDIO.wav\n",
            " File not found: all_audio/701_AUDIO.wav\n",
            "Processing all_audio/702_AUDIO.wav...\n",
            "\n",
            " CSV saved at: /content/drive/MyDrive/CGS_Audio_FacialData/transcripts/702_transcript.csv\n",
            "Processing all_audio/703_AUDIO.wav...\n",
            "\n",
            " CSV saved at: /content/drive/MyDrive/CGS_Audio_FacialData/transcripts/703_transcript.csv\n",
            " File not found: all_audio/704_AUDIO.wav\n",
            " File not found: all_audio/705_AUDIO.wav\n",
            " File not found: all_audio/706_AUDIO.wav\n",
            "Processing all_audio/707_AUDIO.wav...\n",
            "\n",
            " CSV saved at: /content/drive/MyDrive/CGS_Audio_FacialData/transcripts/707_transcript.csv\n",
            " File not found: all_audio/708_AUDIO.wav\n",
            " File not found: all_audio/709_AUDIO.wav\n",
            " File not found: all_audio/710_AUDIO.wav\n",
            " File not found: all_audio/711_AUDIO.wav\n",
            " File not found: all_audio/712_AUDIO.wav\n",
            " File not found: all_audio/713_AUDIO.wav\n",
            " File not found: all_audio/714_AUDIO.wav\n",
            " File not found: all_audio/715_AUDIO.wav\n",
            " File not found: all_audio/716_AUDIO.wav\n",
            " File not found: all_audio/717_AUDIO.wav\n",
            " File not found: all_audio/718_AUDIO.wav\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "from shutil import move\n",
        "\n",
        "# Create output folders\n",
        "drive_csv = \"/content/drive/MyDrive/CGS_Audio_FacialData/all_fau\"\n",
        "os.makedirs(drive_csv, exist_ok=True)\n",
        "\n",
        "rang = [\n",
        "    300, 301, 306, 317, 320, 321, 331, 334, 336, 343, 344, 347, 350,\n",
        "    365, 371, 373, 374, 381, 382, 388, 393, 401, 402, 408, 412, 415,\n",
        "    423, 425, 431, 433, 435, 437, 441, 442, 448, 451, 454, 455, 465,\n",
        "    468, 473, 475, 479, 480, 484, 486, 617, 627, 632, 653, 657, 667,\n",
        "    670, 687, 698, 713,\n",
        "    600, 602, 604, 605, 606, 607, 609, 615, 618, 619, 620, 622, 623,\n",
        "    624, 625, 626, 629, 631, 634, 635, 636, 637, 638, 640, 649, 650,\n",
        "    651, 652, 655, 656, 658, 659, 661, 663, 664, 666, 669, 676, 679,\n",
        "    682, 683, 688, 689, 691, 693, 696, 699, 705, 708, 709, 710, 712,\n",
        "    715, 716, 717, 718,\n",
        "    673, 677, 680, 684, 692, 695, 697, 702, 703, 707\n",
        "]\n",
        "\n",
        "\n",
        "for i in rang:\n",
        "    pid = f\"{i}_P\"\n",
        "    archive = f\"{pid}.tar.gz\"\n",
        "    url = f\"https://dcapswoz.ict.usc.edu/wwwedaic/data/{archive}\"\n",
        "\n",
        "    print(f\"\\nðŸ“¥ Downloading: {archive}\")\n",
        "    os.system(f\"wget -q --show-progress {url}\")\n",
        "\n",
        "    print(f\"ðŸ“¦ Extracting audio and CSV from: {archive}\")\n",
        "    os.system(f\"tar --wildcards -xzf {archive} '{pid}/features/*OpenFace2.1.0_Pose_gaze_AUs.csv'\")\n",
        "\n",
        "    print(f\"ðŸ§¹ Removing archive: {archive}\")\n",
        "    os.system(f\"rm {archive}\")\n",
        "\n",
        "    # Move the extracted files to organized folders\n",
        "    csv_path = Path(f\"{pid}/features/{pid.replace('_P','')}_OpenFace2.1.0_Pose_gaze_AUs.csv\")\n",
        "\n",
        "    if csv_path.exists():\n",
        "        move(str(csv_path), f\"{drive_csv}/{csv_path.name}\")\n",
        "\n",
        "    # Optional: delete the now-empty folder\n",
        "    os.system(f\"rm -rf {pid}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64468f98-76a3-4531-c516-164faec9779b",
        "id": "n-urmsKlDvGM"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“¥ Downloading: 300_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 300_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 300_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 301_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 301_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 301_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 306_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 306_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 306_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 317_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 317_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 317_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 320_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 320_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 320_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 321_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 321_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 321_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 331_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 331_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 331_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 334_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 334_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 334_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 336_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 336_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 336_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 343_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 343_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 343_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 344_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 344_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 344_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 347_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 347_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 347_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 350_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 350_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 350_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 365_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 365_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 365_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 371_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 371_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 371_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 373_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 373_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 373_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 374_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 374_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 374_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 381_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 381_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 381_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 382_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 382_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 382_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 388_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 388_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 388_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 393_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 393_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 393_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 401_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 401_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 401_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 402_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 402_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 402_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 408_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 408_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 408_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 412_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 412_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 412_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 415_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 415_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 415_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 423_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 423_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 423_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 425_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 425_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 425_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 431_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 431_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 431_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 433_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 433_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 433_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 435_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 435_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 435_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 437_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 437_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 437_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 441_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 441_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 441_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 442_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 442_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 442_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 448_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 448_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 448_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 451_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 451_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 451_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 454_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 454_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 454_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 455_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 455_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 455_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 465_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 465_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 465_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 468_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 468_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 468_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 473_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 473_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 473_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 475_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 475_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 475_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 479_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 479_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 479_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 480_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 480_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 480_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 484_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 484_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 484_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 486_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 486_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 486_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 617_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 617_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 617_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 627_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 627_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 627_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 632_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 632_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 632_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 653_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 653_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 653_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 657_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 657_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 657_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 667_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 667_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 667_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 670_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 670_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 670_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 687_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 687_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 687_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 698_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 698_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 698_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 713_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 713_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 713_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 600_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 600_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 600_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 602_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 602_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 602_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 604_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 604_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 604_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 605_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 605_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 605_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 606_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 606_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 606_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 607_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 607_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 607_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 609_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 609_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 609_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 615_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 615_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 615_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 618_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 618_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 618_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 619_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 619_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 619_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 620_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 620_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 620_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 622_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 622_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 622_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 623_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 623_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 623_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 624_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 624_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 624_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 625_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 625_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 625_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 626_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 626_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 626_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 629_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 629_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 629_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 631_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 631_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 631_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 634_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 634_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 634_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 635_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 635_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 635_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 636_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 636_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 636_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 637_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 637_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 637_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 638_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 638_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 638_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 640_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 640_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 640_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 649_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 649_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 649_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 650_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 650_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 650_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 651_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 651_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 651_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 652_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 652_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 652_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 655_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 655_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 655_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 656_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 656_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 656_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 658_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 658_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 658_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 659_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 659_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 659_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 661_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 661_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 661_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 663_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 663_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 663_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 664_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 664_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 664_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 666_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 666_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 666_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 669_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 669_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 669_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 676_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 676_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 676_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 679_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 679_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 679_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 682_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 682_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 682_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 683_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 683_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 683_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 688_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 688_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 688_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 689_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 689_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 689_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 691_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 691_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 691_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 693_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 693_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 693_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 696_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 696_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 696_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 699_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 699_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 699_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 705_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 705_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 705_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 708_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 708_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 708_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 709_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 709_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 709_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 710_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 710_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 710_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 712_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 712_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 712_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 715_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 715_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 715_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 716_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 716_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 716_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 717_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 717_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 717_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 718_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 718_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 718_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 673_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 673_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 673_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 677_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 677_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 677_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 680_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 680_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 680_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 684_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 684_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 684_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 692_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 692_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 692_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 695_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 695_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 695_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 697_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 697_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 697_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 702_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 702_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 702_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 703_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 703_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 703_P.tar.gz\n",
            "\n",
            "ðŸ“¥ Downloading: 707_P.tar.gz\n",
            "ðŸ“¦ Extracting audio and CSV from: 707_P.tar.gz\n",
            "ðŸ§¹ Removing archive: 707_P.tar.gz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Paths to your CSV files\n",
        "file1 = '/content/618_BoAW_openSMILE_2.3.0_MFCC.csv'\n",
        "file2 = '/content/618_BoAW_openSMILE_2.3.0_eGeMAPS.csv'\n",
        "\n",
        "# Load the CSV files (semicolon-separated)\n",
        "df1 = pd.read_csv(file1, sep=';', header = None)\n",
        "df2 = pd.read_csv(file2, sep=';', header = None)\n",
        "\n",
        "df1 = df1.iloc[:, 1:]\n",
        "df2 = df2.iloc[:, 2:]\n",
        "\n",
        "# Concatenate along columns (side by side)\n",
        "merged_df = pd.concat([df1, df2], axis=1)\n",
        "\n",
        "# Save to a new CSV file\n",
        "output_file = '/content/drive/MyDrive/Feature_Datasets/BoAW_combined/618_BoAW_openSMILE_2.3.0_combined.csv'\n",
        "merged_df.to_csv(output_file, index=False, header=None)\n",
        "\n",
        "print(f\"Merged CSV saved to: {output_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBxPOiSzsbQb",
        "outputId": "375f2372-9f5c-49ab-8813-d7651f304c07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Merged CSV saved to: /content/drive/MyDrive/Feature_Datasets/BoAW_combined/618_BoAW_openSMILE_2.3.0_combined.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# Move a single file\n",
        "shutil.move('/content/691_BoAW_openSMILE_2.3.0_combined.csv', '/content/drive/MyDrive/Feature_Datasets/BoAW_combined/691_BoAW_openSMILE_2.3.0_combined.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "BP85cw_8uzWS",
        "outputId": "b4797c03-2fcd-4c49-fd3e-6f01e13f02dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/Feature_Datasets/BoAW_combined/691_BoAW_openSMILE_2.3.0_combined.csv'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# Folder to zip\n",
        "folder_path = '/content/drive/MyDrive/CGS_Audio_FacialData/all_fau'\n",
        "\n",
        "# Output zip file path (without .zip extension)\n",
        "zip_path = '/content/drive/MyDrive/CGS_Audio_FacialData/all_fau.zip'\n",
        "\n",
        "# Create the zip archive\n",
        "shutil.make_archive(zip_path, 'zip', folder_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "xShFXG73zIcn",
        "outputId": "32306700-3bea-4b12-9e3c-2c084ecd8749"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/CGS_Audio_FacialData/all_fau.zip.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "EO_0nwpEqiaH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transcript_path = '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts'\n",
        "audio_path = '/content/drive/MyDrive/Feature_Datasets/BoAW_combined'"
      ],
      "metadata": {
        "id": "KBB9vCqbpN6C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "UTTERANCES_PER_CHUNK = 12\n",
        "OVERLAP = 6\n",
        "MAX_CHUNKS = 87"
      ],
      "metadata": {
        "id": "XRmIHeR_pVxo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audio_data = []\n",
        "\n",
        "transcript_path = '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts'\n",
        "fau_path = '/content/drive/MyDrive/Feature_Datasets/BoAW_combined'\n",
        "\n",
        "for person_id in range(300, 719):\n",
        "    try:\n",
        "        transcript_file = os.path.join(transcript_path, f'{person_id}_transcript.csv')\n",
        "        fau_file_1 = os.path.join(fau_path, f'{person_id}_BoAW_openSMILE_2.3.0_combined.csv')\n",
        "\n",
        "        transcript_df = pd.read_csv(transcript_file)\n",
        "        fau_df_1 = pd.read_csv(fau_file_1, header=None)  # Assuming no column names\n",
        "\n",
        "        chunks = []\n",
        "        utterance_features = []\n",
        "\n",
        "        for _, row in transcript_df.iterrows():\n",
        "            start, end = row['start'], row['end']\n",
        "\n",
        "            # Select segment between start and end time\n",
        "            segment_1 = fau_df_1[(fau_df_1.iloc[:, 0] >= start) & (fau_df_1.iloc[:, 0] <= end)]\n",
        "\n",
        "            feature_cols = fau_df_1.shape[1] - 1  # exclude timestamp\n",
        "            if segment_1.empty:\n",
        "                pooled_1 = np.zeros(feature_cols)\n",
        "            else:\n",
        "                pooled_1 = segment_1.iloc[:, 1:].max().values  # max over feature columns only\n",
        "\n",
        "            utterance_features.append(pooled_1)\n",
        "\n",
        "        # Chunking with overlap\n",
        "        for i in range(0, len(utterance_features) - UTTERANCES_PER_CHUNK + 1, UTTERANCES_PER_CHUNK - OVERLAP):\n",
        "            chunk = np.vstack(utterance_features[i:i + UTTERANCES_PER_CHUNK])\n",
        "            chunk_pooled = chunk.max(axis=0)\n",
        "            chunks.append(chunk_pooled)\n",
        "\n",
        "        # Padding to MAX_CHUNKS\n",
        "        while len(chunks) < MAX_CHUNKS:\n",
        "            chunks.append(np.zeros(feature_cols))\n",
        "        chunks = chunks[:MAX_CHUNKS]\n",
        "\n",
        "        audio_data.append(np.array(chunks))\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error with {person_id}: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2d47R5YPyaRG",
        "outputId": "70c360f5-d52d-4d2f-8024-7ac4ead36b48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error with 342: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/342_transcript.csv'\n",
            "Error with 394: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/394_transcript.csv'\n",
            "Error with 398: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/398_transcript.csv'\n",
            "Error with 460: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/460_transcript.csv'\n",
            "Error with 493: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/493_transcript.csv'\n",
            "Error with 494: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/494_transcript.csv'\n",
            "Error with 495: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/495_transcript.csv'\n",
            "Error with 496: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/496_transcript.csv'\n",
            "Error with 497: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/497_transcript.csv'\n",
            "Error with 498: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/498_transcript.csv'\n",
            "Error with 499: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/499_transcript.csv'\n",
            "Error with 500: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/500_transcript.csv'\n",
            "Error with 501: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/501_transcript.csv'\n",
            "Error with 502: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/502_transcript.csv'\n",
            "Error with 503: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/503_transcript.csv'\n",
            "Error with 504: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/504_transcript.csv'\n",
            "Error with 505: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/505_transcript.csv'\n",
            "Error with 506: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/506_transcript.csv'\n",
            "Error with 507: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/507_transcript.csv'\n",
            "Error with 508: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/508_transcript.csv'\n",
            "Error with 509: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/509_transcript.csv'\n",
            "Error with 510: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/510_transcript.csv'\n",
            "Error with 511: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/511_transcript.csv'\n",
            "Error with 512: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/512_transcript.csv'\n",
            "Error with 513: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/513_transcript.csv'\n",
            "Error with 514: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/514_transcript.csv'\n",
            "Error with 515: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/515_transcript.csv'\n",
            "Error with 516: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/516_transcript.csv'\n",
            "Error with 517: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/517_transcript.csv'\n",
            "Error with 518: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/518_transcript.csv'\n",
            "Error with 519: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/519_transcript.csv'\n",
            "Error with 520: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/520_transcript.csv'\n",
            "Error with 521: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/521_transcript.csv'\n",
            "Error with 522: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/522_transcript.csv'\n",
            "Error with 523: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/523_transcript.csv'\n",
            "Error with 524: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/524_transcript.csv'\n",
            "Error with 525: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/525_transcript.csv'\n",
            "Error with 526: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/526_transcript.csv'\n",
            "Error with 527: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/527_transcript.csv'\n",
            "Error with 528: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/528_transcript.csv'\n",
            "Error with 529: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/529_transcript.csv'\n",
            "Error with 530: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/530_transcript.csv'\n",
            "Error with 531: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/531_transcript.csv'\n",
            "Error with 532: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/532_transcript.csv'\n",
            "Error with 533: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/533_transcript.csv'\n",
            "Error with 534: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/534_transcript.csv'\n",
            "Error with 535: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/535_transcript.csv'\n",
            "Error with 536: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/536_transcript.csv'\n",
            "Error with 537: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/537_transcript.csv'\n",
            "Error with 538: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/538_transcript.csv'\n",
            "Error with 539: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/539_transcript.csv'\n",
            "Error with 540: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/540_transcript.csv'\n",
            "Error with 541: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/541_transcript.csv'\n",
            "Error with 542: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/542_transcript.csv'\n",
            "Error with 543: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/543_transcript.csv'\n",
            "Error with 544: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/544_transcript.csv'\n",
            "Error with 545: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/545_transcript.csv'\n",
            "Error with 546: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/546_transcript.csv'\n",
            "Error with 547: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/547_transcript.csv'\n",
            "Error with 548: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/548_transcript.csv'\n",
            "Error with 549: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/549_transcript.csv'\n",
            "Error with 550: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/550_transcript.csv'\n",
            "Error with 551: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/551_transcript.csv'\n",
            "Error with 552: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/552_transcript.csv'\n",
            "Error with 553: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/553_transcript.csv'\n",
            "Error with 554: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/554_transcript.csv'\n",
            "Error with 555: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/555_transcript.csv'\n",
            "Error with 556: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/556_transcript.csv'\n",
            "Error with 557: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/557_transcript.csv'\n",
            "Error with 558: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/558_transcript.csv'\n",
            "Error with 559: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/559_transcript.csv'\n",
            "Error with 560: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/560_transcript.csv'\n",
            "Error with 561: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/561_transcript.csv'\n",
            "Error with 562: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/562_transcript.csv'\n",
            "Error with 563: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/563_transcript.csv'\n",
            "Error with 564: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/564_transcript.csv'\n",
            "Error with 565: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/565_transcript.csv'\n",
            "Error with 566: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/566_transcript.csv'\n",
            "Error with 567: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/567_transcript.csv'\n",
            "Error with 568: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/568_transcript.csv'\n",
            "Error with 569: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/569_transcript.csv'\n",
            "Error with 570: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/570_transcript.csv'\n",
            "Error with 571: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/571_transcript.csv'\n",
            "Error with 572: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/572_transcript.csv'\n",
            "Error with 573: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/573_transcript.csv'\n",
            "Error with 574: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/574_transcript.csv'\n",
            "Error with 575: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/575_transcript.csv'\n",
            "Error with 576: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/576_transcript.csv'\n",
            "Error with 577: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/577_transcript.csv'\n",
            "Error with 578: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/578_transcript.csv'\n",
            "Error with 579: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/579_transcript.csv'\n",
            "Error with 580: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/580_transcript.csv'\n",
            "Error with 581: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/581_transcript.csv'\n",
            "Error with 582: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/582_transcript.csv'\n",
            "Error with 583: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/583_transcript.csv'\n",
            "Error with 584: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/584_transcript.csv'\n",
            "Error with 585: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/585_transcript.csv'\n",
            "Error with 586: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/586_transcript.csv'\n",
            "Error with 587: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/587_transcript.csv'\n",
            "Error with 588: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/588_transcript.csv'\n",
            "Error with 589: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/589_transcript.csv'\n",
            "Error with 590: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/590_transcript.csv'\n",
            "Error with 591: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/591_transcript.csv'\n",
            "Error with 592: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/592_transcript.csv'\n",
            "Error with 593: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/593_transcript.csv'\n",
            "Error with 594: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/594_transcript.csv'\n",
            "Error with 595: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/595_transcript.csv'\n",
            "Error with 596: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/596_transcript.csv'\n",
            "Error with 597: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/597_transcript.csv'\n",
            "Error with 598: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/598_transcript.csv'\n",
            "Error with 599: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/599_transcript.csv'\n",
            "Error with 610: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/610_transcript.csv'\n",
            "Error with 611: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/611_transcript.csv'\n",
            "Error with 613: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/613_transcript.csv'\n",
            "Error with 614: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/614_transcript.csv'\n",
            "Error with 616: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/616_transcript.csv'\n",
            "Error with 621: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/621_transcript.csv'\n",
            "Error with 630: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/630_transcript.csv'\n",
            "Error with 639: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/639_transcript.csv'\n",
            "Error with 642: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/642_transcript.csv'\n",
            "Error with 643: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/643_transcript.csv'\n",
            "Error with 644: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/644_transcript.csv'\n",
            "Error with 645: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/645_transcript.csv'\n",
            "Error with 646: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/646_transcript.csv'\n",
            "Error with 647: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/647_transcript.csv'\n",
            "Error with 648: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/648_transcript.csv'\n",
            "Error with 665: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/665_transcript.csv'\n",
            "Error with 668: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/668_transcript.csv'\n",
            "Error with 671: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/671_transcript.csv'\n",
            "Error with 672: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/672_transcript.csv'\n",
            "Error with 674: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/674_transcript.csv'\n",
            "Error with 675: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/675_transcript.csv'\n",
            "Error with 678: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/678_transcript.csv'\n",
            "Error with 681: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/681_transcript.csv'\n",
            "Error with 685: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/685_transcript.csv'\n",
            "Error with 686: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/686_transcript.csv'\n",
            "Error with 690: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/690_transcript.csv'\n",
            "Error with 694: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/694_transcript.csv'\n",
            "Error with 700: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/700_transcript.csv'\n",
            "Error with 701: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/701_transcript.csv'\n",
            "Error with 704: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/704_transcript.csv'\n",
            "Error with 706: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/706_transcript.csv'\n",
            "Error with 711: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/711_transcript.csv'\n",
            "Error with 714: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/714_transcript.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/CGS_Audio_FacialData/all_csv_train.zip -d /content/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5hMcP8Z5O2e",
        "outputId": "e3fa4fee-582a-4801-cd15-0c185e089673"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/CGS_Audio_FacialData/all_csv_train.zip\n",
            " extracting: /content/302_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/303_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/304_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/305_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/307_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/308_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/309_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/310_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/311_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/312_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/313_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/314_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/315_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/316_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/318_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/319_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/322_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/323_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/324_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/325_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/326_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/327_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/328_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/329_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/330_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/332_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/333_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/335_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/337_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/338_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/339_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/340_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/341_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/345_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/346_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/348_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/349_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/351_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/352_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/353_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/354_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/355_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/356_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/357_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/358_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/359_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/360_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/361_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/362_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/363_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/364_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/366_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/367_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/368_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/369_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/370_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/372_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/375_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/376_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/377_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/378_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/379_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/380_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/383_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/384_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/385_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/386_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/387_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/389_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/390_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/391_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/392_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/395_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/396_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/397_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/399_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/400_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/403_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/404_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/405_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/406_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/407_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/409_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/410_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/411_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/413_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/414_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/416_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/417_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/418_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/419_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/420_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/421_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/422_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/424_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/426_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/427_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/428_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/429_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/430_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/432_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/434_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/436_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/438_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/439_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/440_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/443_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/444_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/445_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/446_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/447_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/449_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/450_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/452_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/453_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/456_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/457_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/458_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/459_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/461_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/462_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/463_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/464_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/466_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/467_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/469_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/470_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/471_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/472_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/474_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/476_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/477_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/478_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/481_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/482_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/483_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/485_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/487_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/488_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/489_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/490_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/491_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/492_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/601_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/603_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/608_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/612_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/628_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/633_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/641_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/654_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/660_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            " extracting: /content/662_OpenFace2.1.0_Pose_gaze_AUs.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/CGS_Audio_FacialData/all_fau.zip.zip -d /content/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cgR64xZe5PYo",
        "outputId": "ae40cf87-1b11-4b28-cab0-a700324e8eeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/CGS_Audio_FacialData/all_fau.zip.zip\n",
            "  inflating: /content/331_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/334_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/336_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/343_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/344_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/347_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/350_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/365_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/371_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/373_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/374_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/381_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/382_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/388_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/393_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/401_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/402_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/408_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/412_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/415_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/423_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/425_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/431_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/433_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/435_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/437_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/441_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/442_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/448_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/451_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/454_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/455_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/465_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/468_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/473_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/475_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/479_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/480_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/484_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/486_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/617_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/623_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/627_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/632_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/653_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/657_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/667_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/670_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/673_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/677_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/680_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/684_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/687_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/692_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/695_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/697_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/698_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/702_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/703_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/707_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/713_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/300_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/301_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/306_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/600_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/602_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/604_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/605_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/606_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/607_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/609_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/615_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/618_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/619_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/620_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/317_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/320_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/321_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/622_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/625_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/626_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/629_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/631_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/634_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/635_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/636_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/637_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/638_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/640_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/649_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/650_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/651_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/652_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/655_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/656_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/658_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/659_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/661_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/663_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/664_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/666_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/669_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/676_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/679_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/682_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/683_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/688_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/689_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/691_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/693_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/696_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/699_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/705_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/708_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/709_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/710_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/712_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/715_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/716_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/717_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/718_OpenFace2.1.0_Pose_gaze_AUs.csv  \n",
            "  inflating: /content/624_OpenFace2.1.0_Pose_gaze_AUs.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "FAU_FEATURE_COLS = ['frame', 'confidence', 'success']"
      ],
      "metadata": {
        "id": "FLvAlsd16mL1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PeuNmHFhsO9s",
        "outputId": "2897fcc7-0e64-48e2-cace-731961818b5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error with 342: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/342_transcript.csv'\n",
            "Error with 394: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/394_transcript.csv'\n",
            "Error with 398: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/398_transcript.csv'\n",
            "Error with 460: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/460_transcript.csv'\n",
            "Error with 493: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/493_transcript.csv'\n",
            "Error with 494: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/494_transcript.csv'\n",
            "Error with 495: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/495_transcript.csv'\n",
            "Error with 496: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/496_transcript.csv'\n",
            "Error with 497: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/497_transcript.csv'\n",
            "Error with 498: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/498_transcript.csv'\n",
            "Error with 499: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/499_transcript.csv'\n",
            "Error with 500: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/500_transcript.csv'\n",
            "Error with 501: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/501_transcript.csv'\n",
            "Error with 502: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/502_transcript.csv'\n",
            "Error with 503: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/503_transcript.csv'\n",
            "Error with 504: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/504_transcript.csv'\n",
            "Error with 505: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/505_transcript.csv'\n",
            "Error with 506: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/506_transcript.csv'\n",
            "Error with 507: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/507_transcript.csv'\n",
            "Error with 508: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/508_transcript.csv'\n",
            "Error with 509: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/509_transcript.csv'\n",
            "Error with 510: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/510_transcript.csv'\n",
            "Error with 511: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/511_transcript.csv'\n",
            "Error with 512: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/512_transcript.csv'\n",
            "Error with 513: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/513_transcript.csv'\n",
            "Error with 514: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/514_transcript.csv'\n",
            "Error with 515: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/515_transcript.csv'\n",
            "Error with 516: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/516_transcript.csv'\n",
            "Error with 517: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/517_transcript.csv'\n",
            "Error with 518: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/518_transcript.csv'\n",
            "Error with 519: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/519_transcript.csv'\n",
            "Error with 520: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/520_transcript.csv'\n",
            "Error with 521: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/521_transcript.csv'\n",
            "Error with 522: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/522_transcript.csv'\n",
            "Error with 523: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/523_transcript.csv'\n",
            "Error with 524: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/524_transcript.csv'\n",
            "Error with 525: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/525_transcript.csv'\n",
            "Error with 526: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/526_transcript.csv'\n",
            "Error with 527: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/527_transcript.csv'\n",
            "Error with 528: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/528_transcript.csv'\n",
            "Error with 529: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/529_transcript.csv'\n",
            "Error with 530: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/530_transcript.csv'\n",
            "Error with 531: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/531_transcript.csv'\n",
            "Error with 532: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/532_transcript.csv'\n",
            "Error with 533: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/533_transcript.csv'\n",
            "Error with 534: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/534_transcript.csv'\n",
            "Error with 535: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/535_transcript.csv'\n",
            "Error with 536: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/536_transcript.csv'\n",
            "Error with 537: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/537_transcript.csv'\n",
            "Error with 538: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/538_transcript.csv'\n",
            "Error with 539: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/539_transcript.csv'\n",
            "Error with 540: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/540_transcript.csv'\n",
            "Error with 541: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/541_transcript.csv'\n",
            "Error with 542: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/542_transcript.csv'\n",
            "Error with 543: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/543_transcript.csv'\n",
            "Error with 544: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/544_transcript.csv'\n",
            "Error with 545: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/545_transcript.csv'\n",
            "Error with 546: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/546_transcript.csv'\n",
            "Error with 547: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/547_transcript.csv'\n",
            "Error with 548: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/548_transcript.csv'\n",
            "Error with 549: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/549_transcript.csv'\n",
            "Error with 550: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/550_transcript.csv'\n",
            "Error with 551: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/551_transcript.csv'\n",
            "Error with 552: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/552_transcript.csv'\n",
            "Error with 553: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/553_transcript.csv'\n",
            "Error with 554: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/554_transcript.csv'\n",
            "Error with 555: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/555_transcript.csv'\n",
            "Error with 556: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/556_transcript.csv'\n",
            "Error with 557: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/557_transcript.csv'\n",
            "Error with 558: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/558_transcript.csv'\n",
            "Error with 559: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/559_transcript.csv'\n",
            "Error with 560: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/560_transcript.csv'\n",
            "Error with 561: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/561_transcript.csv'\n",
            "Error with 562: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/562_transcript.csv'\n",
            "Error with 563: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/563_transcript.csv'\n",
            "Error with 564: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/564_transcript.csv'\n",
            "Error with 565: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/565_transcript.csv'\n",
            "Error with 566: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/566_transcript.csv'\n",
            "Error with 567: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/567_transcript.csv'\n",
            "Error with 568: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/568_transcript.csv'\n",
            "Error with 569: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/569_transcript.csv'\n",
            "Error with 570: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/570_transcript.csv'\n",
            "Error with 571: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/571_transcript.csv'\n",
            "Error with 572: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/572_transcript.csv'\n",
            "Error with 573: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/573_transcript.csv'\n",
            "Error with 574: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/574_transcript.csv'\n",
            "Error with 575: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/575_transcript.csv'\n",
            "Error with 576: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/576_transcript.csv'\n",
            "Error with 577: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/577_transcript.csv'\n",
            "Error with 578: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/578_transcript.csv'\n",
            "Error with 579: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/579_transcript.csv'\n",
            "Error with 580: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/580_transcript.csv'\n",
            "Error with 581: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/581_transcript.csv'\n",
            "Error with 582: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/582_transcript.csv'\n",
            "Error with 583: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/583_transcript.csv'\n",
            "Error with 584: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/584_transcript.csv'\n",
            "Error with 585: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/585_transcript.csv'\n",
            "Error with 586: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/586_transcript.csv'\n",
            "Error with 587: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/587_transcript.csv'\n",
            "Error with 588: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/588_transcript.csv'\n",
            "Error with 589: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/589_transcript.csv'\n",
            "Error with 590: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/590_transcript.csv'\n",
            "Error with 591: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/591_transcript.csv'\n",
            "Error with 592: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/592_transcript.csv'\n",
            "Error with 593: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/593_transcript.csv'\n",
            "Error with 594: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/594_transcript.csv'\n",
            "Error with 595: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/595_transcript.csv'\n",
            "Error with 596: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/596_transcript.csv'\n",
            "Error with 597: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/597_transcript.csv'\n",
            "Error with 598: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/598_transcript.csv'\n",
            "Error with 599: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/599_transcript.csv'\n",
            "Error with 610: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/610_transcript.csv'\n",
            "Error with 611: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/611_transcript.csv'\n",
            "Error with 613: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/613_transcript.csv'\n",
            "Error with 614: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/614_transcript.csv'\n",
            "Error with 616: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/616_transcript.csv'\n",
            "Error with 621: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/621_transcript.csv'\n",
            "Error with 630: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/630_transcript.csv'\n",
            "Error with 639: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/639_transcript.csv'\n",
            "Error with 642: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/642_transcript.csv'\n",
            "Error with 643: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/643_transcript.csv'\n",
            "Error with 644: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/644_transcript.csv'\n",
            "Error with 645: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/645_transcript.csv'\n",
            "Error with 646: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/646_transcript.csv'\n",
            "Error with 647: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/647_transcript.csv'\n",
            "Error with 648: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/648_transcript.csv'\n",
            "Error with 665: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/665_transcript.csv'\n",
            "Error with 668: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/668_transcript.csv'\n",
            "Error with 671: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/671_transcript.csv'\n",
            "Error with 672: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/672_transcript.csv'\n",
            "Error with 674: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/674_transcript.csv'\n",
            "Error with 675: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/675_transcript.csv'\n",
            "Error with 678: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/678_transcript.csv'\n",
            "Error with 681: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/681_transcript.csv'\n",
            "Error with 685: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/685_transcript.csv'\n",
            "Error with 686: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/686_transcript.csv'\n",
            "Error with 690: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/690_transcript.csv'\n",
            "Error with 694: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/694_transcript.csv'\n",
            "Error with 700: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/700_transcript.csv'\n",
            "Error with 701: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/701_transcript.csv'\n",
            "Error with 704: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/704_transcript.csv'\n",
            "Error with 706: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/706_transcript.csv'\n",
            "Error with 711: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/711_transcript.csv'\n",
            "Error with 714: [Errno 2] No such file or directory: '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts/714_transcript.csv'\n"
          ]
        }
      ],
      "source": [
        "video_data = []\n",
        "\n",
        "transcript_path = '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts'\n",
        "fau_path = '/content/'\n",
        "\n",
        "for person_id in range(300, 719):\n",
        "    try:\n",
        "        transcript_file = os.path.join(transcript_path, f'{person_id}_transcript.csv')\n",
        "        fau_file = os.path.join(fau_path, f'{person_id}_OpenFace2.1.0_Pose_gaze_AUs.csv')\n",
        "\n",
        "        transcript_df = pd.read_csv(transcript_file)\n",
        "\n",
        "        # Only load timestamp + FAU features\n",
        "        # Get all columns\n",
        "        all_columns = pd.read_csv(fau_file, nrows=0).columns.tolist()\n",
        "\n",
        "        # Keep everything except the ones in FAU_FEATURE_COLS\n",
        "        columns_to_use = [col for col in all_columns if col not in FAU_FEATURE_COLS]\n",
        "\n",
        "        # Load only the selected columns\n",
        "        fau_df = pd.read_csv(fau_file, usecols=columns_to_use)\n",
        "\n",
        "\n",
        "        chunks = []\n",
        "        utterance_features = []\n",
        "\n",
        "        for _, row in transcript_df.iterrows():\n",
        "            start, end = row['start'], row['end']\n",
        "            segment = fau_df[(fau_df['timestamp'] >= start) & (fau_df['timestamp'] <= end)]\n",
        "            feature_columns = [col for col in fau_df.columns if col != 'timestamp']\n",
        "\n",
        "            if segment.empty:\n",
        "                pooled = np.zeros(len(feature_columns))\n",
        "            else:\n",
        "                pooled = segment[feature_columns].max().values\n",
        "\n",
        "            utterance_features.append(pooled)\n",
        "\n",
        "        # Chunking with overlap\n",
        "        for i in range(0, len(utterance_features) - UTTERANCES_PER_CHUNK + 1, UTTERANCES_PER_CHUNK - OVERLAP):\n",
        "            chunk = np.vstack(utterance_features[i:i+UTTERANCES_PER_CHUNK])\n",
        "            chunk_pooled = chunk.max(axis=0)\n",
        "            chunks.append(chunk_pooled)\n",
        "\n",
        "        # Padding\n",
        "        while len(chunks) < MAX_CHUNKS:\n",
        "            chunks.append(np.zeros(len(feature_columns)))\n",
        "        chunks = chunks[:MAX_CHUNKS]\n",
        "\n",
        "        video_data.append(np.array(chunks))\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error with {person_id}: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_PQqpogaTWq8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming the 'transcripts' folder contains segmented CSV files for each participant\n",
        "transcript_folder = '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts'\n",
        "transcripts_data = {}\n",
        "\n",
        "# Load each CSV file into a dictionary\n",
        "for participant_id in range(300, 719):\n",
        "    file_path = os.path.join(transcript_folder, f\"{participant_id}_transcript.csv\")\n",
        "    if os.path.exists(file_path):\n",
        "        df = pd.read_csv(file_path)  # Load the CSV\n",
        "        transcripts_data[participant_id] = df['text'].tolist()  # Get list of text utterances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wesY4c4VUQJU"
      },
      "outputs": [],
      "source": [
        "def chunk_transcript(utterances, chunk_size=10, overlap=4):\n",
        "    step = chunk_size - overlap\n",
        "    chunks = []\n",
        "    for i in range(0, len(utterances) - chunk_size + 1, step):\n",
        "        chunk = utterances[i:i + chunk_size]\n",
        "        chunks.append(\" \".join(chunk))  # Join the chunks into a single string\n",
        "    return chunks\n",
        "\n",
        "# Apply chunking to each participant's transcript\n",
        "chunks_data = {}\n",
        "for participant_id, utterances in transcripts_data.items():\n",
        "    chunks_data[participant_id] = chunk_transcript(utterances)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v7I-pRZ7UTM0"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
        "\n",
        "def get_embedding(text):\n",
        "    # Generate embeddings for the input text\n",
        "    return model.encode(text).tolist()  # Convert numpy array to list\n",
        "\n",
        "# Embed all chunks for each participant\n",
        "embeddings_data = {}\n",
        "for participant_id, chunks in chunks_data.items():\n",
        "    embeddings_data[participant_id] = [get_embedding(chunk) for chunk in chunks]"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "23Isqek0755I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YB_faW5RUZtM"
      },
      "outputs": [],
      "source": [
        "# Create a list of PTSD severity scores and corresponding embeddings\n",
        "text_data = []  # Store embeddings\n",
        "\n",
        "for participant_id, embeddings in embeddings_data.items():\n",
        "    text_data.append(embeddings)  # Add embeddings"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "audio_data = np.array(audio_data)\n",
        "audio_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AsZwqf4o9_7g",
        "outputId": "872a3ae2-eef2-42a0-da8c-c75876d12163"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(275, 87, 200)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "video_data = np.array(video_data)\n",
        "video_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KaaPucwp-EyP",
        "outputId": "451a476e-c895-4e2b-dc60-273a4f4e82c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(275, 87, 49)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "embedding_dim = len(text_data[0])  # e.g., 1536 for `text-embedding-small`\n",
        "\n",
        "# Pad sequences to ensure consistent input size\n",
        "MAX_CHUNKS = 87\n",
        "text_data = pad_sequences(text_data, padding='post', dtype='float32', maxlen=MAX_CHUNKS)\n",
        "\n",
        "# Convert to numpy arrays\n",
        "text_data = np.array(text_data)"
      ],
      "metadata": {
        "id": "C-0-UaFh-LlO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gq2-zqC6-ZUa",
        "outputId": "b50f9201-b7de-40c8-db32-f36cc2720574"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(275, 87, 384)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_all = np.concatenate([audio_data, text_data, video_data], axis=2)"
      ],
      "metadata": {
        "id": "sVQvdoEp-i32"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "transcript_path = '/content/drive/MyDrive/CGS_Audio_FacialData/transcripts'\n",
        "\n",
        "rows = []\n",
        "\n",
        "# Track current index into X_all\n",
        "sample_idx = 0\n",
        "\n",
        "for person_id in range(300, 719):\n",
        "    transcript_file = os.path.join(transcript_path, f'{person_id}_transcript.csv')\n",
        "    if os.path.exists(transcript_file):\n",
        "        # X_all[sample_idx] shape: (chunks, features)\n",
        "        for chunk_id, chunk in enumerate(X_all[sample_idx]):\n",
        "            row = {\n",
        "                'participant_id': person_id,\n",
        "                'chunk_id': chunk_id\n",
        "            }\n",
        "            # Add features with column names like feature_0, feature_1, ...\n",
        "            feature_dict = {f'feature_{i}': value for i, value in enumerate(chunk)}\n",
        "            row.update(feature_dict)\n",
        "            rows.append(row)\n",
        "\n",
        "        sample_idx += 1  # Move to next participant in X_all\n",
        "\n",
        "# Convert to DataFrame\n",
        "df = pd.DataFrame(rows)\n",
        "\n",
        "# Save to CSV\n",
        "df.to_csv('/content/drive/MyDrive/X_all_flat_with_ids.csv', index=False)\n"
      ],
      "metadata": {
        "id": "MGhQJVGNA9WC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}