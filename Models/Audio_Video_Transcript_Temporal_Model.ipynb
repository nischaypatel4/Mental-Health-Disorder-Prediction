{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CX74--PYeN1n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "797c3bef-3172-4ac4-a940-e6605e063b38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "summary_features = pd.read_csv('/content/participant_summary_new.csv')\n",
        "#summary_features = pd.read_csv('/content/drive/My Drive/full_participant_summary.csv')\n",
        "\n",
        "print(summary_features.shape)"
      ],
      "metadata": {
        "id": "t9oM3pLbeZM8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d150d6d-bdc5-4c96-edac-181ac8214ee5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(275, 1014)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_names = []\n",
        "for i in range(1, 50):  # f1 to f49\n",
        "    for stat in ['mean', 'std', 'min', 'max']:\n",
        "        new_names.append(f'OpenFace_f{i}_{stat}')\n",
        "\n",
        "# Apply renaming to your dataframe\n",
        "column_indices_to_rename = range(802, 998)  # Inclusive of 802 to 997\n",
        "summary_features.columns.values[list(column_indices_to_rename)] = new_names"
      ],
      "metadata": {
        "id": "onic0RhXTq5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary_features = summary_features.loc[:, (summary_features != 0).any(axis=0)]"
      ],
      "metadata": {
        "id": "PdaYuuyISmea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load your label CSV\n",
        "df = pd.read_csv('/content/GroundTruth Table.csv')\n",
        "\n",
        "# Define labels\n",
        "labels = ['PTSD_Label',\t'Depression_Label',\t'Appetite_Label',\t'Agency_Label',\t'Anxiety_Label',\t'Sleep_Label']\n",
        "\n",
        "# Plot\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "x = range(len(labels))\n",
        "zeros = [df[label].value_counts().get(0, 0) for label in labels]\n",
        "ones = [df[label].value_counts().get(1, 0) for label in labels]\n",
        "\n",
        "bar_width = 0.35\n",
        "ax.bar([i - bar_width/2 for i in x], zeros, width=bar_width, label='Class 0')\n",
        "ax.bar([i + bar_width/2 for i in x], ones, width=bar_width, label='Class 1')\n",
        "\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(labels, rotation=45, ha='right')\n",
        "ax.set_ylabel('Count')\n",
        "ax.set_title('Class Distribution per Label')\n",
        "ax.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DJBMTXhEA-7Y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "outputId": "a102ecf3-264b-4dd6-e79a-8ed96fbcd198"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
        "from sklearn.svm import SVC\n",
        "import xgboost as xgb\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "\n",
        "# Separate features (summary_features) and the identified labels\n",
        "X = summary_features\n",
        "y = df[labels[0]] #i =0, 1, 2, 3, 4, 5 for diffrent targets\n",
        "\n",
        "# Initialize StratifiedKFold with 5 splits\n",
        "n_splits = 5  # Set to 5 for 5 iterations/folds\n",
        "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)"
      ],
      "metadata": {
        "id": "UDl-FWhxq94O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORSxAkMluoxQ",
        "outputId": "380f3b7c-11ff-4a58-d57a-f4c3ce32ca29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(275,)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pns81jeeuYff",
        "outputId": "f0ff1e63-395d-49cf-df70-1d870bd74c84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(275, 806)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = summary_features.copy()\n",
        "\n",
        "# Label encoding for categoricals\n",
        "for colname in X.select_dtypes(\"object\"):\n",
        "    X[colname], _ = X[colname].factorize()\n",
        "\n",
        "# All discrete features should now have integer dtypes (double-check this before using MI!)\n",
        "discrete_features = X.dtypes == int"
      ],
      "metadata": {
        "id": "0LCpJKv9pJw5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "discrete_features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "Q0HalCqCuc-_",
        "outputId": "a877f48b-1ad7-475c-f117-8553117e533e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "participant_id            True\n",
              "eGeMAPS_f1_mean          False\n",
              "eGeMAPS_f1_std           False\n",
              "eGeMAPS_f1_max           False\n",
              "eGeMAPS_f2_mean          False\n",
              "                         ...  \n",
              "depression_word_count     True\n",
              "anxiety_word_count        True\n",
              "stress_word_count         True\n",
              "ptsd_word_count           True\n",
              "harm_word_count           True\n",
              "Length: 806, dtype: bool"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>participant_id</th>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>eGeMAPS_f1_mean</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>eGeMAPS_f1_std</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>eGeMAPS_f1_max</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>eGeMAPS_f2_mean</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>depression_word_count</th>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>anxiety_word_count</th>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>stress_word_count</th>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ptsd_word_count</th>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>harm_word_count</th>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>806 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> bool</label>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4P47sE-ZsMqB",
        "outputId": "22b024f1-0d10-4462-f2a1-6e352b2af314"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(275, 806)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "u0QS2Go7sOWk",
        "outputId": "7d848cf8-bae9-4ea1-c2f0-ed2df6642170"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   participant_id  eGeMAPS_f1_mean  eGeMAPS_f1_std  eGeMAPS_f1_max  \\\n",
              "0             300         0.339651        0.412770        1.633468   \n",
              "1             301         0.417114        0.383984        1.462398   \n",
              "2             302         0.431654        0.399046        1.414973   \n",
              "3             303         0.688838        0.391137        1.544068   \n",
              "4             304         0.594773        0.377326        1.477121   \n",
              "\n",
              "   eGeMAPS_f2_mean  eGeMAPS_f2_std  eGeMAPS_f2_max  eGeMAPS_f3_mean  \\\n",
              "0         0.309486        0.527131        2.008600         0.098401   \n",
              "1         0.508682        0.565141        1.963788         0.048905   \n",
              "2         0.008801        0.083450        1.041393         0.070662   \n",
              "3         1.028125        0.639955        2.037427         0.041777   \n",
              "4         0.658804        0.659056        1.977724         0.043229   \n",
              "\n",
              "   eGeMAPS_f3_std  eGeMAPS_f3_max  ...  lexical_diversity  \\\n",
              "0        0.224203        1.079181  ...           0.336842   \n",
              "1        0.167753        1.000000  ...           0.238649   \n",
              "2        0.204610        0.954242  ...           0.330756   \n",
              "3        0.147273        0.954242  ...           0.211736   \n",
              "4        0.154882        0.903090  ...           0.269373   \n",
              "\n",
              "   first_person_pronoun_count  negation_count  sleep_word_count  \\\n",
              "0                          62               9                 1   \n",
              "1                         150              23                 1   \n",
              "2                          81              13                 1   \n",
              "3                         164              16                 6   \n",
              "4                         120              21                 4   \n",
              "\n",
              "   appetite_word_count  depression_word_count  anxiety_word_count  \\\n",
              "0                    0                      2                   1   \n",
              "1                    0                      3                   1   \n",
              "2                    2                      2                   2   \n",
              "3                    1                      3                   2   \n",
              "4                    0                      1                   1   \n",
              "\n",
              "   stress_word_count  ptsd_word_count  harm_word_count  \n",
              "0                  0                1                2  \n",
              "1                  1                3                2  \n",
              "2                  0                1                2  \n",
              "3                  1                3                1  \n",
              "4                  0                2                1  \n",
              "\n",
              "[5 rows x 806 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ef5bfe62-48dd-490f-b723-515b4ac0ed04\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>participant_id</th>\n",
              "      <th>eGeMAPS_f1_mean</th>\n",
              "      <th>eGeMAPS_f1_std</th>\n",
              "      <th>eGeMAPS_f1_max</th>\n",
              "      <th>eGeMAPS_f2_mean</th>\n",
              "      <th>eGeMAPS_f2_std</th>\n",
              "      <th>eGeMAPS_f2_max</th>\n",
              "      <th>eGeMAPS_f3_mean</th>\n",
              "      <th>eGeMAPS_f3_std</th>\n",
              "      <th>eGeMAPS_f3_max</th>\n",
              "      <th>...</th>\n",
              "      <th>lexical_diversity</th>\n",
              "      <th>first_person_pronoun_count</th>\n",
              "      <th>negation_count</th>\n",
              "      <th>sleep_word_count</th>\n",
              "      <th>appetite_word_count</th>\n",
              "      <th>depression_word_count</th>\n",
              "      <th>anxiety_word_count</th>\n",
              "      <th>stress_word_count</th>\n",
              "      <th>ptsd_word_count</th>\n",
              "      <th>harm_word_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>300</td>\n",
              "      <td>0.339651</td>\n",
              "      <td>0.412770</td>\n",
              "      <td>1.633468</td>\n",
              "      <td>0.309486</td>\n",
              "      <td>0.527131</td>\n",
              "      <td>2.008600</td>\n",
              "      <td>0.098401</td>\n",
              "      <td>0.224203</td>\n",
              "      <td>1.079181</td>\n",
              "      <td>...</td>\n",
              "      <td>0.336842</td>\n",
              "      <td>62</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>301</td>\n",
              "      <td>0.417114</td>\n",
              "      <td>0.383984</td>\n",
              "      <td>1.462398</td>\n",
              "      <td>0.508682</td>\n",
              "      <td>0.565141</td>\n",
              "      <td>1.963788</td>\n",
              "      <td>0.048905</td>\n",
              "      <td>0.167753</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.238649</td>\n",
              "      <td>150</td>\n",
              "      <td>23</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>302</td>\n",
              "      <td>0.431654</td>\n",
              "      <td>0.399046</td>\n",
              "      <td>1.414973</td>\n",
              "      <td>0.008801</td>\n",
              "      <td>0.083450</td>\n",
              "      <td>1.041393</td>\n",
              "      <td>0.070662</td>\n",
              "      <td>0.204610</td>\n",
              "      <td>0.954242</td>\n",
              "      <td>...</td>\n",
              "      <td>0.330756</td>\n",
              "      <td>81</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>303</td>\n",
              "      <td>0.688838</td>\n",
              "      <td>0.391137</td>\n",
              "      <td>1.544068</td>\n",
              "      <td>1.028125</td>\n",
              "      <td>0.639955</td>\n",
              "      <td>2.037427</td>\n",
              "      <td>0.041777</td>\n",
              "      <td>0.147273</td>\n",
              "      <td>0.954242</td>\n",
              "      <td>...</td>\n",
              "      <td>0.211736</td>\n",
              "      <td>164</td>\n",
              "      <td>16</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>304</td>\n",
              "      <td>0.594773</td>\n",
              "      <td>0.377326</td>\n",
              "      <td>1.477121</td>\n",
              "      <td>0.658804</td>\n",
              "      <td>0.659056</td>\n",
              "      <td>1.977724</td>\n",
              "      <td>0.043229</td>\n",
              "      <td>0.154882</td>\n",
              "      <td>0.903090</td>\n",
              "      <td>...</td>\n",
              "      <td>0.269373</td>\n",
              "      <td>120</td>\n",
              "      <td>21</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 806 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ef5bfe62-48dd-490f-b723-515b4ac0ed04')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ef5bfe62-48dd-490f-b723-515b4ac0ed04 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ef5bfe62-48dd-490f-b723-515b4ac0ed04');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-b49e95d2-e60d-45ff-954e-e849022f2751\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b49e95d2-e60d-45ff-954e-e849022f2751')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-b49e95d2-e60d-45ff-954e-e849022f2751 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "X"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6CV8hWGOuie2",
        "outputId": "2b715e63-874e-4e00-ee49-9efff066dd75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(275,)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import mutual_info_classif\n"
      ],
      "metadata": {
        "id": "W1DjRVdLpbBG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_mi_scores(X, y, discrete_features):\n",
        "    mi_scores = mutual_info_classif(X, y, discrete_features=discrete_features)\n",
        "    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n",
        "\n",
        "    return mi_scores\n",
        "\n",
        "# mi_scores = make_mi_scores(X, y, discrete_features)\n",
        "# mi_scores  # show a few features with their MI scores"
      ],
      "metadata": {
        "id": "hngO45Nks7SH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "PP5UNx7n28yB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model for Temporal Features (CNN+BILSTM)"
      ],
      "metadata": {
        "id": "IJGP_U_GI-Y7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, Bidirectional, LSTM, Dense, Input, BatchNormalization, GlobalMaxPooling1D, Dropout\n",
        "from tensorflow.keras.losses import MeanAbsoluteError\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "iAvnAvWgDL_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_CHUNKS = 87"
      ],
      "metadata": {
        "id": "hAeHmeEeC8br"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "def apply_pca(X_all):\n",
        "  pca = PCA(n_components=40)  # or 50, depending on desired reduction\n",
        "  X_embed_scaled = StandardScaler().fit_transform(X_all.iloc[:,-384:])\n",
        "\n",
        "  X_reduced = pca.fit_transform(X_embed_scaled)\n",
        "\n",
        "  # Explained variance ratio for each component\n",
        "  explained_variance_ratio = pca.explained_variance_ratio_\n",
        "\n",
        "  # Cumulative explained variance\n",
        "  cumulative_variance = np.cumsum(explained_variance_ratio)\n",
        "\n",
        "  # Replacing SBERT embeddings with PCs\n",
        "  # Step 1: Drop the last 384 columns\n",
        "  X_all = X_all.iloc[:, :-384]\n",
        "\n",
        "  # Step 2: Convert X_reduced (NumPy array) to DataFrame\n",
        "  X_reduced_df = pd.DataFrame(X_reduced, index=X_all.index)\n",
        "\n",
        "  # Optional: rename columns\n",
        "  X_reduced_df.columns = [f'embed_{i}' for i in range(X_reduced_df.shape[1])]\n",
        "\n",
        "  # Step 3: Concatenate\n",
        "  X_all = pd.concat([X_all, X_reduced_df], axis=1)\n",
        "  return X_all"
      ],
      "metadata": {
        "id": "5U0CN2UcP6on"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Input, Conv1D, BatchNormalization, Dropout, Bidirectional, LSTM, GlobalMaxPooling1D, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "import re\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "\n",
        "def scheduler(epoch, lr):\n",
        "    if epoch < 20:\n",
        "        return lr\n",
        "    elif epoch == 20:\n",
        "        return lr * 0.1\n",
        "    elif epoch == 40:\n",
        "        return lr * 0.1\n",
        "    else:\n",
        "        return lr\n",
        "\n",
        "lr_scheduler = LearningRateScheduler(scheduler, verbose=1)\n",
        "\n",
        "# Wrap your model in a function\n",
        "def build_model(input_shape):\n",
        "    model = Sequential([\n",
        "        Input(shape=input_shape),\n",
        "        Conv1D(64, kernel_size=3, activation='relu', padding='same'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.3),\n",
        "        Bidirectional(LSTM(64, return_sequences=True)),\n",
        "        GlobalMaxPooling1D(),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dropout(0.3),\n",
        "        Dense(16, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')  # Binary classification\n",
        "    ])\n",
        "    model.compile(optimizer=Adam(1e-3), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def build_model_ragged(input_dim):\n",
        "    inp = Input(shape=(None, input_dim))  # variable-length support\n",
        "\n",
        "    x = Conv1D(4, kernel_size=5, activation='relu')(inp)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "\n",
        "    # x = SimpleRNN(4, return_sequences=True)(x)\n",
        "    x = Bidirectional(LSTM(4, return_sequences=True))(x)\n",
        "    x = GlobalMaxPooling1D()(x)\n",
        "\n",
        "    x = Dense(4, activation='tanh')(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    out = Dense(2, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs=inp, outputs=out)\n",
        "    model.compile(optimizer=Adam(learning_rate=0.01), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def remove_padding(X):\n",
        "    sequences = []\n",
        "    for x in X:\n",
        "        # Find non-zero time steps (axis=1 because time is axis 0 in x)\n",
        "        non_zero_mask = np.any(x != 0, axis=1)\n",
        "        trimmed = x[non_zero_mask]\n",
        "        sequences.append(trimmed)\n",
        "    return sequences\n"
      ],
      "metadata": {
        "id": "DvKDq2zmEN5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TEMPORAL FEATURES MODEL"
      ],
      "metadata": {
        "id": "ncS74BK8J5T8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Function to compute metrics\n",
        "def compute_metrics_dl(y_true, y_pred):\n",
        "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "    acc = (tp + tn) / (tp + tn + fp + fn)\n",
        "    sens = tp / (tp + fn) if (tp + fn) else 0\n",
        "    spec = tn / (tn + fp) if (tn + fp) else 0\n",
        "    return round(acc, 4), round(sens, 4), round(spec, 4)\n",
        "\n",
        "# Result holder: label -> [acc, sens, spec]\n",
        "results_dl = {}\n",
        "df = pd.read_csv('/content/GroundTruth Table.csv')\n",
        "MAX_CHUNKS = 87\n",
        "# Replace these with your actual label list and data (X_all_label, y_all_label)\n",
        "labels = ['Appetite_Label', 'Anxiety_Label', 'Sleep_Label', 'Agency_Label', 'Depression_Label', 'PTSD_Label']\n",
        "extracted_features = []\n",
        "extra_features = [f\"feature_{i}\" for i in range(249, 633)]\n",
        "extracted_features.extend(extra_features)\n",
        "\n",
        "X_all_label = pd.read_csv('/content/All_features.csv', usecols = extracted_features)  # shape: (samples, MAX_CHUNKS, features) for this label\n",
        "print(X_all_label.shape)\n",
        "X_all_label = apply_pca(X_all_label)\n",
        "\n",
        "for label in labels:\n",
        "    # X = summary_features.copy()\n",
        "    # y = df[label]\n",
        "\n",
        "    # discrete_features = [False] * X.shape[1]\n",
        "    # mi_scores = make_mi_scores(X, y, discrete_features)\n",
        "    # filtered_scores = mi_scores[mi_scores > 0]\n",
        "    # filtered_X = X[filtered_scores.index]\n",
        "\n",
        "    # # Drop highly correlated features\n",
        "    # corr_matrix = filtered_X.corr().abs()\n",
        "    # to_drop = {\n",
        "    #     col2 if filtered_scores[col1] >= filtered_scores[col2] else col1\n",
        "    #     for i, col1 in enumerate(corr_matrix.columns)\n",
        "    #     for j, col2 in enumerate(corr_matrix.columns)\n",
        "    #     if i < j and corr_matrix.loc[col1, col2] > 0.8\n",
        "    # }\n",
        "\n",
        "    # final_X = filtered_X.drop(columns=to_drop)\n",
        "    # final_scores = filtered_scores.drop(labels=to_drop)\n",
        "\n",
        "    # # Select top 20% features\n",
        "    # top_features = final_scores.sort_values(ascending=False).head(int(len(final_scores) * 0.2))\n",
        "    # top_features_list = top_features.index.tolist()\n",
        "\n",
        "    # extracted_features = []\n",
        "\n",
        "    # for feature in top_features_list:\n",
        "    #     match = re.match(r'^(MFCC|eGeMAPS|FAU)_f(\\d+)_((?:mean)|(?:std)|(?:min)|(?:max))$', feature)\n",
        "    #     if match:\n",
        "    #         category, number, _ = match.groups()\n",
        "    #         number = int(number)\n",
        "    #         if category == \"MFCC\":\n",
        "    #             mapped = f\"feature_{number-1}\"\n",
        "    #         elif category == \"eGeMAPS\":\n",
        "    #             mapped = f\"feature_{number + 100-1}\"\n",
        "    #         # elif category == \"FAU\":\n",
        "    #         #     mapped = f\"feature_{number + 200-1}\"\n",
        "    #         extracted_features.append(mapped)\n",
        "    # # extra_features = [f\"feature_{i}\" for i in range(249, 633)]\n",
        "    # # extracted_features.extend(extra_features)\n",
        "\n",
        "\n",
        "    print(f\"\\n=== Deep Learning on {label} ===\")\n",
        "    y_all_label = df[label] # binary labels for this label\n",
        "    X_all_label = np.array(X_all_label)\n",
        "    print(X_all_label.shape)\n",
        "    X_all_label = X_all_label.reshape(275, 87, -1)\n",
        "    print(X_all_label.shape)\n",
        "\n",
        "\n",
        "    fold_metrics = []\n",
        "\n",
        "    kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    for train_index, test_index in kf.split(X_all_label, y_all_label):\n",
        "        X_train, X_test = X_all_label[train_index], X_all_label[test_index]\n",
        "        y_train, y_test = y_all_label[train_index], y_all_label[test_index]\n",
        "\n",
        "        X_flat = X_train.reshape((X_train.shape[0], -1))\n",
        "        ros = RandomOverSampler()\n",
        "        X_resampled, y_resampled = ros.fit_resample(X_flat, y_train)\n",
        "        X_train = X_resampled.reshape((-1, 87, X_train.shape[2]))\n",
        "        y_train = to_categorical(y_resampled)\n",
        "\n",
        "        X_train = X_train[:,:,:]\n",
        "        X_test = X_test[:,:,:]\n",
        "\n",
        "        X_train = remove_padding(X_train)\n",
        "        X_test = remove_padding(X_test)\n",
        "\n",
        "        X_train = tf.ragged.constant(X_train, dtype=tf.float32)\n",
        "        X_test = tf.ragged.constant(X_test, dtype=tf.float32)\n",
        "        y_test = to_categorical(y_test)\n",
        "\n",
        "        X_train = X_train.to_tensor()\n",
        "        X_test = X_test.to_tensor()\n",
        "\n",
        "        model = build_model_ragged(input_dim=X_train.shape[2])\n",
        "        model.fit(X_train, y_train, batch_size=16, epochs=15, validation_data=(X_test, y_test), callbacks=[lr_scheduler], verbose=1, shuffle=True)\n",
        "\n",
        "        y_pred_prob = model.predict(X_test)\n",
        "        y_pred = (y_pred_prob > 0.5).astype(int)\n",
        "        y_pred = np.argmax(y_pred_prob, axis=1)\n",
        "        y_test = np.argmax(y_test, axis=1)\n",
        "        acc, sens, spec = compute_metrics_dl(y_test, y_pred)\n",
        "        fold_metrics.append((acc, sens, spec))\n",
        "\n",
        "    avg_metrics = np.mean(fold_metrics, axis=0)\n",
        "    results_dl[label] = list(map(lambda x: round(x, 4), avg_metrics))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZUQYA_3obk-",
        "outputId": "d68e57d1-1869-4a12-8865-cdb274f744bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(23925, 384)\n",
            "\n",
            "=== Deep Learning on Appetite_Label ===\n",
            "(23925, 40)\n",
            "(275, 87, 40)\n",
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 1/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 144ms/step - accuracy: 0.5516 - loss: 0.7220 - val_accuracy: 0.7455 - val_loss: 0.5496 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 2/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - accuracy: 0.6338 - loss: 0.6501 - val_accuracy: 0.8000 - val_loss: 0.5322 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 3/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.7273 - loss: 0.6046 - val_accuracy: 0.7636 - val_loss: 0.4840 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 4/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.7415 - loss: 0.5832 - val_accuracy: 0.8182 - val_loss: 0.4839 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 5/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.7804 - loss: 0.5057 - val_accuracy: 0.7455 - val_loss: 0.5335 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 6/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.8230 - loss: 0.4588 - val_accuracy: 0.7636 - val_loss: 0.5167 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 7/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.7710 - loss: 0.4992 - val_accuracy: 0.6727 - val_loss: 0.7057 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 8/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.8435 - loss: 0.4085 - val_accuracy: 0.6909 - val_loss: 0.7702 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 9/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 0.8137 - loss: 0.4222 - val_accuracy: 0.7273 - val_loss: 0.7133 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 10/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - accuracy: 0.8297 - loss: 0.4060 - val_accuracy: 0.7455 - val_loss: 0.6691 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 11: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 11/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.8392 - loss: 0.3424 - val_accuracy: 0.7455 - val_loss: 0.7452 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 12: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 12/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9049 - loss: 0.3043 - val_accuracy: 0.7455 - val_loss: 0.6968 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 13: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 13/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.8930 - loss: 0.3074 - val_accuracy: 0.7636 - val_loss: 0.8282 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 14: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 14/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.8973 - loss: 0.2600 - val_accuracy: 0.7455 - val_loss: 0.8479 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 15: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 15/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9288 - loss: 0.2393 - val_accuracy: 0.7091 - val_loss: 0.9034 - learning_rate: 0.0100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 579ms/step\n",
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 1/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 88ms/step - accuracy: 0.5479 - loss: 0.7061 - val_accuracy: 0.5273 - val_loss: 0.6681 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 2/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - accuracy: 0.5808 - loss: 0.6631 - val_accuracy: 0.7091 - val_loss: 0.6002 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 3/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - accuracy: 0.7035 - loss: 0.5827 - val_accuracy: 0.7273 - val_loss: 0.5532 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 4/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 0.7658 - loss: 0.5284 - val_accuracy: 0.7455 - val_loss: 0.5328 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 5/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.7901 - loss: 0.4356 - val_accuracy: 0.7091 - val_loss: 0.5377 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 6/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.8261 - loss: 0.4090 - val_accuracy: 0.7455 - val_loss: 0.5499 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 7/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.8546 - loss: 0.3754 - val_accuracy: 0.7818 - val_loss: 0.5220 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 8/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.8362 - loss: 0.3735 - val_accuracy: 0.7455 - val_loss: 0.4666 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 9/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.8668 - loss: 0.3384 - val_accuracy: 0.7273 - val_loss: 0.5185 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 10/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.8447 - loss: 0.3728 - val_accuracy: 0.7273 - val_loss: 0.4979 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 11: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 11/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.8887 - loss: 0.2829 - val_accuracy: 0.7818 - val_loss: 0.5370 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 12: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 12/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.8210 - loss: 0.4650 - val_accuracy: 0.7273 - val_loss: 0.5331 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 13: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 13/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.8923 - loss: 0.2866 - val_accuracy: 0.7455 - val_loss: 0.4570 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 14: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 14/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9232 - loss: 0.2290 - val_accuracy: 0.7091 - val_loss: 0.5554 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 15: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 15/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.9162 - loss: 0.2602 - val_accuracy: 0.7273 - val_loss: 0.5427 - learning_rate: 0.0100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 400ms/step\n",
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 1/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 132ms/step - accuracy: 0.4863 - loss: 0.7386 - val_accuracy: 0.2545 - val_loss: 0.7273 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 2/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.6024 - loss: 0.6557 - val_accuracy: 0.2545 - val_loss: 0.8026 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 3/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.6148 - loss: 0.6416 - val_accuracy: 0.4182 - val_loss: 0.7521 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 4/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.7423 - loss: 0.5840 - val_accuracy: 0.4000 - val_loss: 0.8592 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 5/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.7884 - loss: 0.5134 - val_accuracy: 0.4182 - val_loss: 0.8976 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 6/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.7397 - loss: 0.5207 - val_accuracy: 0.4182 - val_loss: 0.8800 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 7/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.8191 - loss: 0.4545 - val_accuracy: 0.5091 - val_loss: 0.8038 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 8/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.8296 - loss: 0.4367 - val_accuracy: 0.5455 - val_loss: 0.7961 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 9/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.8777 - loss: 0.3367 - val_accuracy: 0.5091 - val_loss: 0.9124 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 10/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.8661 - loss: 0.3746 - val_accuracy: 0.5636 - val_loss: 0.8930 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 11: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 11/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.8897 - loss: 0.3532 - val_accuracy: 0.5273 - val_loss: 1.1143 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 12: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 12/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.8646 - loss: 0.3338 - val_accuracy: 0.4545 - val_loss: 1.1731 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 13: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 13/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.8211 - loss: 0.3564 - val_accuracy: 0.5455 - val_loss: 1.0781 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 14: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 14/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.8747 - loss: 0.3058 - val_accuracy: 0.6000 - val_loss: 1.0871 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 15: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 15/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.8864 - loss: 0.3375 - val_accuracy: 0.6182 - val_loss: 1.0976 - learning_rate: 0.0100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 453ms/step\n",
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 1/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.5233 - loss: 0.7549 - val_accuracy: 0.5273 - val_loss: 0.6868 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 2/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.5399 - loss: 0.7030 - val_accuracy: 0.4727 - val_loss: 0.6826 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 3/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.4942 - loss: 0.6925 - val_accuracy: 0.4364 - val_loss: 0.6891 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 4/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.5637 - loss: 0.6832 - val_accuracy: 0.4909 - val_loss: 0.6956 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 5/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.5892 - loss: 0.6720 - val_accuracy: 0.7091 - val_loss: 0.6178 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 6/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 89ms/step - accuracy: 0.7519 - loss: 0.6026 - val_accuracy: 0.6909 - val_loss: 0.6189 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 7/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.7601 - loss: 0.5348 - val_accuracy: 0.7455 - val_loss: 0.5394 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 8/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.8003 - loss: 0.4620 - val_accuracy: 0.7273 - val_loss: 0.6035 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 9/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.8321 - loss: 0.3996 - val_accuracy: 0.7273 - val_loss: 0.6872 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 10/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.8295 - loss: 0.3989 - val_accuracy: 0.7091 - val_loss: 0.8302 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 11: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 11/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.8492 - loss: 0.3153 - val_accuracy: 0.6909 - val_loss: 0.8595 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 12: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 12/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.8859 - loss: 0.3162 - val_accuracy: 0.7091 - val_loss: 0.8665 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 13: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 13/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.8656 - loss: 0.3102 - val_accuracy: 0.7091 - val_loss: 0.8908 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 14: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 14/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.8467 - loss: 0.3654 - val_accuracy: 0.7091 - val_loss: 0.8867 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 15: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 15/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - accuracy: 0.8598 - loss: 0.3416 - val_accuracy: 0.7273 - val_loss: 0.8816 - learning_rate: 0.0100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 412ms/step\n",
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 1/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.5830 - loss: 0.6880 - val_accuracy: 0.5273 - val_loss: 0.6826 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 2/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 94ms/step - accuracy: 0.5505 - loss: 0.6844 - val_accuracy: 0.3091 - val_loss: 0.8358 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 3/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.5638 - loss: 0.6755 - val_accuracy: 0.3636 - val_loss: 0.7879 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 4/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.6588 - loss: 0.6226 - val_accuracy: 0.3818 - val_loss: 0.8178 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 5/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.6951 - loss: 0.5936 - val_accuracy: 0.4182 - val_loss: 0.8409 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 6/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.7572 - loss: 0.5130 - val_accuracy: 0.5273 - val_loss: 0.8005 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 7/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.8070 - loss: 0.4309 - val_accuracy: 0.5636 - val_loss: 0.7391 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 8/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.8032 - loss: 0.4343 - val_accuracy: 0.6000 - val_loss: 0.7765 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 9/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.8595 - loss: 0.4057 - val_accuracy: 0.5818 - val_loss: 0.9074 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 10/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.8132 - loss: 0.4235 - val_accuracy: 0.6364 - val_loss: 0.7942 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 11: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 11/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.8493 - loss: 0.3844 - val_accuracy: 0.4727 - val_loss: 1.0717 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 12: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 12/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 86ms/step - accuracy: 0.8442 - loss: 0.3317 - val_accuracy: 0.5273 - val_loss: 1.1430 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 13: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 13/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.8485 - loss: 0.3336 - val_accuracy: 0.5091 - val_loss: 1.3266 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 14: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 14/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 0.8938 - loss: 0.2485 - val_accuracy: 0.5455 - val_loss: 1.2240 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 15: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 15/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.8642 - loss: 0.2983 - val_accuracy: 0.5091 - val_loss: 1.3397 - learning_rate: 0.0100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 414ms/step\n",
            "\n",
            "=== Deep Learning on Anxiety_Label ===\n",
            "(275, 87, 40)\n",
            "(275, 87, 40)\n",
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 1/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 132ms/step - accuracy: 0.5606 - loss: 0.7800 - val_accuracy: 0.6000 - val_loss: 0.6748 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 2/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.4838 - loss: 0.7297 - val_accuracy: 0.5818 - val_loss: 0.6926 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 3/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.5599 - loss: 0.6716 - val_accuracy: 0.5091 - val_loss: 0.7046 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 4/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.6216 - loss: 0.6454 - val_accuracy: 0.4545 - val_loss: 0.7132 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 5/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.5752 - loss: 0.6543 - val_accuracy: 0.5455 - val_loss: 0.7198 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 6/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.6419 - loss: 0.6356 - val_accuracy: 0.5636 - val_loss: 0.6456 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 7/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.7520 - loss: 0.5164 - val_accuracy: 0.6182 - val_loss: 0.6435 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 8/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.7765 - loss: 0.4643 - val_accuracy: 0.6364 - val_loss: 0.6743 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 9/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.7780 - loss: 0.4487 - val_accuracy: 0.6727 - val_loss: 0.6007 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 10/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.8220 - loss: 0.4691 - val_accuracy: 0.6364 - val_loss: 0.6560 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 11: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 11/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - accuracy: 0.8276 - loss: 0.4005 - val_accuracy: 0.6364 - val_loss: 0.6468 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 12: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 12/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 0.8520 - loss: 0.4062 - val_accuracy: 0.6909 - val_loss: 0.6462 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 13: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 13/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.8402 - loss: 0.3956 - val_accuracy: 0.6727 - val_loss: 0.6212 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 14: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 14/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.8440 - loss: 0.3732 - val_accuracy: 0.7091 - val_loss: 0.5786 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 15: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 15/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.8437 - loss: 0.3443 - val_accuracy: 0.7455 - val_loss: 0.5720 - learning_rate: 0.0100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 401ms/step\n",
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 1/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 93ms/step - accuracy: 0.5309 - loss: 0.7131 - val_accuracy: 0.5091 - val_loss: 0.6977 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 2/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.6236 - loss: 0.6741 - val_accuracy: 0.4909 - val_loss: 0.7125 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 3/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.6596 - loss: 0.6562 - val_accuracy: 0.4364 - val_loss: 0.7064 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 4/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.5178 - loss: 0.6942 - val_accuracy: 0.5818 - val_loss: 0.6972 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 5/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.5810 - loss: 0.6511 - val_accuracy: 0.6182 - val_loss: 0.6819 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 6/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.6223 - loss: 0.6455 - val_accuracy: 0.5636 - val_loss: 0.6737 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 7/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.6900 - loss: 0.6095 - val_accuracy: 0.5455 - val_loss: 0.6970 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 8/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.6131 - loss: 0.6324 - val_accuracy: 0.5818 - val_loss: 0.7091 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 9/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.8107 - loss: 0.5172 - val_accuracy: 0.5636 - val_loss: 0.7471 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 10/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.7256 - loss: 0.5185 - val_accuracy: 0.5455 - val_loss: 0.7572 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 11: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 11/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - accuracy: 0.7362 - loss: 0.5101 - val_accuracy: 0.5273 - val_loss: 0.7755 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 12: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 12/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 0.7648 - loss: 0.5206 - val_accuracy: 0.5818 - val_loss: 0.7456 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 13: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 13/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.7779 - loss: 0.4842 - val_accuracy: 0.5455 - val_loss: 0.7667 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 14: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 14/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.8055 - loss: 0.4529 - val_accuracy: 0.6182 - val_loss: 0.6790 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 15: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 15/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.8709 - loss: 0.3763 - val_accuracy: 0.5818 - val_loss: 0.7405 - learning_rate: 0.0100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 398ms/step\n",
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 1/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 136ms/step - accuracy: 0.5612 - loss: 0.7689 - val_accuracy: 0.4000 - val_loss: 0.7201 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 2/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.5552 - loss: 0.7138 - val_accuracy: 0.5091 - val_loss: 0.6864 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 3/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.5173 - loss: 0.6755 - val_accuracy: 0.5273 - val_loss: 0.6821 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 4/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.6501 - loss: 0.6402 - val_accuracy: 0.5455 - val_loss: 0.6869 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 5/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.6676 - loss: 0.6296 - val_accuracy: 0.5636 - val_loss: 0.6723 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 6/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.5980 - loss: 0.6354 - val_accuracy: 0.5455 - val_loss: 0.7191 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 7/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.6989 - loss: 0.5732 - val_accuracy: 0.5455 - val_loss: 0.7279 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 8/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.6959 - loss: 0.5882 - val_accuracy: 0.6364 - val_loss: 0.6963 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 9/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.7674 - loss: 0.5231 - val_accuracy: 0.6545 - val_loss: 0.7272 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 10/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - accuracy: 0.7549 - loss: 0.5184 - val_accuracy: 0.6545 - val_loss: 0.7100 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 11: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 11/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - accuracy: 0.7920 - loss: 0.4663 - val_accuracy: 0.6000 - val_loss: 0.7281 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 12: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 12/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.7786 - loss: 0.5040 - val_accuracy: 0.6000 - val_loss: 0.7639 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 13: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 13/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.7853 - loss: 0.4699 - val_accuracy: 0.6364 - val_loss: 0.7670 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 14: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 14/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.8167 - loss: 0.4453 - val_accuracy: 0.6364 - val_loss: 0.7882 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 15: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 15/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.8149 - loss: 0.3952 - val_accuracy: 0.6545 - val_loss: 0.8208 - learning_rate: 0.0100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 441ms/step\n",
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 1/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 118ms/step - accuracy: 0.4750 - loss: 0.7458 - val_accuracy: 0.4909 - val_loss: 0.7043 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 2/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - accuracy: 0.4977 - loss: 0.7050 - val_accuracy: 0.5091 - val_loss: 0.6842 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 3/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.6623 - loss: 0.6591 - val_accuracy: 0.6000 - val_loss: 0.6671 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 4/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.6404 - loss: 0.6494 - val_accuracy: 0.6364 - val_loss: 0.6509 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 5/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - accuracy: 0.6486 - loss: 0.6380 - val_accuracy: 0.6182 - val_loss: 0.6392 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 6/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.6565 - loss: 0.6141 - val_accuracy: 0.6182 - val_loss: 0.6714 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 7/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.7366 - loss: 0.5785 - val_accuracy: 0.6364 - val_loss: 0.6794 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 8/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.7329 - loss: 0.5653 - val_accuracy: 0.6727 - val_loss: 0.6281 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 9/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.7939 - loss: 0.5125 - val_accuracy: 0.6364 - val_loss: 0.6876 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 10/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.7859 - loss: 0.5227 - val_accuracy: 0.6364 - val_loss: 0.7234 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 11: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 11/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.7943 - loss: 0.4686 - val_accuracy: 0.5636 - val_loss: 0.7885 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 12: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 12/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.7924 - loss: 0.4596 - val_accuracy: 0.5636 - val_loss: 0.8337 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 13: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 13/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.8012 - loss: 0.4479 - val_accuracy: 0.6000 - val_loss: 0.7603 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 14: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 14/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 110ms/step - accuracy: 0.8537 - loss: 0.4170 - val_accuracy: 0.6545 - val_loss: 0.7622 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 15: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 15/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.7843 - loss: 0.4887 - val_accuracy: 0.6000 - val_loss: 0.8794 - learning_rate: 0.0100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 433ms/step\n",
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 1/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 165ms/step - accuracy: 0.5207 - loss: 0.7008 - val_accuracy: 0.4909 - val_loss: 0.6848 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 2/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - accuracy: 0.5525 - loss: 0.6761 - val_accuracy: 0.6182 - val_loss: 0.6627 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 3/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 0.6138 - loss: 0.6512 - val_accuracy: 0.6727 - val_loss: 0.6363 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 4/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.6923 - loss: 0.5949 - val_accuracy: 0.6909 - val_loss: 0.6131 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 5/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.7433 - loss: 0.5563 - val_accuracy: 0.6545 - val_loss: 0.6018 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 6/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.8069 - loss: 0.4941 - val_accuracy: 0.6000 - val_loss: 0.6649 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 7/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.7890 - loss: 0.5058 - val_accuracy: 0.7091 - val_loss: 0.6605 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 8/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.7791 - loss: 0.5131 - val_accuracy: 0.6727 - val_loss: 0.6772 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 9/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.8045 - loss: 0.4526 - val_accuracy: 0.6727 - val_loss: 0.6668 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 10/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.8062 - loss: 0.4436 - val_accuracy: 0.6909 - val_loss: 0.7164 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 11: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 11/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.8705 - loss: 0.3603 - val_accuracy: 0.6545 - val_loss: 0.7339 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 12: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 12/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.7620 - loss: 0.5031 - val_accuracy: 0.6545 - val_loss: 0.7558 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 13: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 13/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.8596 - loss: 0.3441 - val_accuracy: 0.7455 - val_loss: 0.7096 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 14: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 14/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.8293 - loss: 0.3973 - val_accuracy: 0.7091 - val_loss: 0.6750 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 15: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 15/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.9029 - loss: 0.2672 - val_accuracy: 0.7091 - val_loss: 0.7717 - learning_rate: 0.0100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 436ms/step\n",
            "\n",
            "=== Deep Learning on Sleep_Label ===\n",
            "(275, 87, 40)\n",
            "(275, 87, 40)\n",
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 1/15\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 90ms/step - accuracy: 0.5487 - loss: 0.7192 - val_accuracy: 0.5455 - val_loss: 0.6947 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 2/15\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - accuracy: 0.5617 - loss: 0.6768 - val_accuracy: 0.6364 - val_loss: 0.6362 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 3/15\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.6122 - loss: 0.6569 - val_accuracy: 0.6182 - val_loss: 0.6370 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 4/15\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.6706 - loss: 0.6247 - val_accuracy: 0.6182 - val_loss: 0.6321 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 5/15\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.7035 - loss: 0.5758 - val_accuracy: 0.6182 - val_loss: 0.6348 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 6/15\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.8100 - loss: 0.4852 - val_accuracy: 0.6364 - val_loss: 0.6972 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 7/15\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - accuracy: 0.8233 - loss: 0.4439 - val_accuracy: 0.6182 - val_loss: 0.7784 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 8/15\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - accuracy: 0.8022 - loss: 0.4839 - val_accuracy: 0.6545 - val_loss: 0.7945 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 9/15\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.8478 - loss: 0.3657 - val_accuracy: 0.6182 - val_loss: 0.8399 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 10/15\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.8281 - loss: 0.4103 - val_accuracy: 0.5273 - val_loss: 0.9285 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 11: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 11/15\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.8464 - loss: 0.3593 - val_accuracy: 0.6364 - val_loss: 0.9076 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 12: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 12/15\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.8795 - loss: 0.3540 - val_accuracy: 0.5818 - val_loss: 0.9980 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 13: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 13/15\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9067 - loss: 0.3483 - val_accuracy: 0.5818 - val_loss: 1.0747 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 14: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 14/15\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9075 - loss: 0.2379 - val_accuracy: 0.5818 - val_loss: 1.1593 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 15: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 15/15\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9221 - loss: 0.2099 - val_accuracy: 0.6545 - val_loss: 1.1578 - learning_rate: 0.0100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 415ms/step\n",
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 1/15\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 90ms/step - accuracy: 0.4853 - loss: 0.7239 - val_accuracy: 0.3818 - val_loss: 0.7812 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 2/15\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.5095 - loss: 0.7092 - val_accuracy: 0.3455 - val_loss: 0.7603 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 3/15\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.5929 - loss: 0.6688 - val_accuracy: 0.4364 - val_loss: 0.7274 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 4/15\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.6532 - loss: 0.6536 - val_accuracy: 0.4545 - val_loss: 0.7491 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 5/15\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.7231 - loss: 0.6035 - val_accuracy: 0.4364 - val_loss: 0.8170 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 6/15\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.6954 - loss: 0.5867 - val_accuracy: 0.5091 - val_loss: 0.8252 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 7/15\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - accuracy: 0.8003 - loss: 0.5180 - val_accuracy: 0.5636 - val_loss: 0.7886 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 8/15\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.8310 - loss: 0.4446 - val_accuracy: 0.5636 - val_loss: 0.8556 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 9/15\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.8083 - loss: 0.4344 - val_accuracy: 0.4364 - val_loss: 0.9630 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 10/15\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.7866 - loss: 0.5036 - val_accuracy: 0.5091 - val_loss: 0.8431 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 11: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 11/15\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.8215 - loss: 0.4008 - val_accuracy: 0.5091 - val_loss: 0.9435 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 12: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 12/15\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.8297 - loss: 0.3535 - val_accuracy: 0.6545 - val_loss: 0.7741 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 13: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 13/15\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.8696 - loss: 0.3284 - val_accuracy: 0.5636 - val_loss: 0.9173 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 14: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 14/15\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.8655 - loss: 0.3110 - val_accuracy: 0.5636 - val_loss: 1.0012 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 15: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 15/15\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.8860 - loss: 0.3003 - val_accuracy: 0.4727 - val_loss: 1.3663 - learning_rate: 0.0100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 634ms/step\n",
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 1/15\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.4864 - loss: 0.7429 - val_accuracy: 0.3091 - val_loss: 0.7193 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 2/15\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - accuracy: 0.5101 - loss: 0.7132 - val_accuracy: 0.4000 - val_loss: 0.7136 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 3/15\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - accuracy: 0.5785 - loss: 0.6678 - val_accuracy: 0.4909 - val_loss: 0.7128 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 4/15\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.6826 - loss: 0.6201 - val_accuracy: 0.6545 - val_loss: 0.6505 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 5/15\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - accuracy: 0.6612 - loss: 0.6072 - val_accuracy: 0.6182 - val_loss: 0.6555 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 6/15\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7063 - loss: 0.5695 - val_accuracy: 0.6364 - val_loss: 0.6164 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 7/15\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.8254 - loss: 0.4421 - val_accuracy: 0.6909 - val_loss: 0.6361 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 8/15\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.8636 - loss: 0.3946 - val_accuracy: 0.6364 - val_loss: 0.6580 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 9/15\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.8112 - loss: 0.4149 - val_accuracy: 0.6545 - val_loss: 0.7210 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 10/15\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.8219 - loss: 0.4052 - val_accuracy: 0.6364 - val_loss: 0.7831 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 11: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 11/15\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.8267 - loss: 0.4104 - val_accuracy: 0.5818 - val_loss: 0.7777 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 12: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 12/15\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - accuracy: 0.8428 - loss: 0.3876 - val_accuracy: 0.6727 - val_loss: 0.6388 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 13: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 13/15\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 0.8879 - loss: 0.3343 - val_accuracy: 0.6727 - val_loss: 0.6918 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 14: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 14/15\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.8678 - loss: 0.3650 - val_accuracy: 0.7091 - val_loss: 0.5755 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 15: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 15/15\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.8530 - loss: 0.3804 - val_accuracy: 0.6909 - val_loss: 0.6981 - learning_rate: 0.0100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 398ms/step\n",
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 1/15\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 94ms/step - accuracy: 0.5142 - loss: 0.7096 - val_accuracy: 0.5455 - val_loss: 0.6812 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 2/15\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - accuracy: 0.6123 - loss: 0.6770 - val_accuracy: 0.4727 - val_loss: 0.7216 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 3/15\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.6368 - loss: 0.6483 - val_accuracy: 0.5636 - val_loss: 0.6616 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 4/15\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.6408 - loss: 0.6360 - val_accuracy: 0.6000 - val_loss: 0.6846 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 5/15\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.7078 - loss: 0.5838 - val_accuracy: 0.5818 - val_loss: 0.7909 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 6/15\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.7810 - loss: 0.5480 - val_accuracy: 0.6364 - val_loss: 0.6970 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 7/15\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.7990 - loss: 0.4335 - val_accuracy: 0.6909 - val_loss: 0.7455 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 8/15\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.8269 - loss: 0.4595 - val_accuracy: 0.6727 - val_loss: 0.7015 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 9/15\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - accuracy: 0.8059 - loss: 0.4625 - val_accuracy: 0.5455 - val_loss: 0.8578 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 10/15\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.8595 - loss: 0.3767 - val_accuracy: 0.6545 - val_loss: 0.6770 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 11: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 11/15\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.8216 - loss: 0.3909 - val_accuracy: 0.6364 - val_loss: 0.7425 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 12: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 12/15\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.8700 - loss: 0.3335 - val_accuracy: 0.5818 - val_loss: 0.9537 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 13: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 13/15\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.8735 - loss: 0.3064 - val_accuracy: 0.6545 - val_loss: 0.8178 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 14: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 14/15\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.8647 - loss: 0.3323 - val_accuracy: 0.6182 - val_loss: 0.8296 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 15: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 15/15\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.8765 - loss: 0.3505 - val_accuracy: 0.5818 - val_loss: 0.8649 - learning_rate: 0.0100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 417ms/step\n",
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 1/15\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 93ms/step - accuracy: 0.4896 - loss: 0.7508 - val_accuracy: 0.3636 - val_loss: 0.7932 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 2/15\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.4946 - loss: 0.7042 - val_accuracy: 0.4000 - val_loss: 0.7275 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 3/15\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.5825 - loss: 0.6790 - val_accuracy: 0.4182 - val_loss: 0.7263 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 4/15\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.5838 - loss: 0.6676 - val_accuracy: 0.5273 - val_loss: 0.6712 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 5/15\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - accuracy: 0.6014 - loss: 0.6403 - val_accuracy: 0.6545 - val_loss: 0.6252 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 6/15\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.6406 - loss: 0.6161 - val_accuracy: 0.7273 - val_loss: 0.6072 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 7/15\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.6391 - loss: 0.6042 - val_accuracy: 0.6545 - val_loss: 0.6231 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 8/15\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.6950 - loss: 0.5752 - val_accuracy: 0.7091 - val_loss: 0.5856 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 9/15\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.7724 - loss: 0.5321 - val_accuracy: 0.6000 - val_loss: 0.7496 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 10/15\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.7904 - loss: 0.5020 - val_accuracy: 0.7091 - val_loss: 0.6002 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 11: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 11/15\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - accuracy: 0.8045 - loss: 0.4746 - val_accuracy: 0.6364 - val_loss: 0.7343 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 12: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 12/15\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8323 - loss: 0.4105 - val_accuracy: 0.6727 - val_loss: 0.6531 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 13: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 13/15\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - accuracy: 0.8203 - loss: 0.4327 - val_accuracy: 0.6727 - val_loss: 0.6004 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 14: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 14/15\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - accuracy: 0.8188 - loss: 0.3896 - val_accuracy: 0.6364 - val_loss: 0.7542 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 15: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 15/15\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8453 - loss: 0.3794 - val_accuracy: 0.6909 - val_loss: 0.7066 - learning_rate: 0.0100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 408ms/step\n",
            "\n",
            "=== Deep Learning on Agency_Label ===\n",
            "(275, 87, 40)\n",
            "(275, 87, 40)\n",
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 1/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 148ms/step - accuracy: 0.5252 - loss: 0.7031 - val_accuracy: 0.5091 - val_loss: 0.7022 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 2/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - accuracy: 0.6441 - loss: 0.6703 - val_accuracy: 0.6364 - val_loss: 0.6798 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 3/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - accuracy: 0.5906 - loss: 0.6688 - val_accuracy: 0.5818 - val_loss: 0.6766 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 4/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.6853 - loss: 0.6111 - val_accuracy: 0.6364 - val_loss: 0.6546 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 5/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.7114 - loss: 0.5941 - val_accuracy: 0.7273 - val_loss: 0.6148 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 6/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7449 - loss: 0.5643 - val_accuracy: 0.6545 - val_loss: 0.6395 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 7/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8049 - loss: 0.4724 - val_accuracy: 0.6909 - val_loss: 0.7086 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 8/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.8513 - loss: 0.4265 - val_accuracy: 0.6182 - val_loss: 0.7054 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 9/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.7809 - loss: 0.4280 - val_accuracy: 0.6182 - val_loss: 0.7404 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 10/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.7966 - loss: 0.4749 - val_accuracy: 0.6000 - val_loss: 0.7751 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 11: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 11/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - accuracy: 0.8189 - loss: 0.4490 - val_accuracy: 0.6545 - val_loss: 0.7214 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 12: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 12/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.8629 - loss: 0.4143 - val_accuracy: 0.6727 - val_loss: 0.7505 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 13: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 13/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.8806 - loss: 0.3126 - val_accuracy: 0.6727 - val_loss: 0.8294 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 14: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 14/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.8460 - loss: 0.3723 - val_accuracy: 0.5818 - val_loss: 0.8294 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 15: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 15/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.8641 - loss: 0.3207 - val_accuracy: 0.6909 - val_loss: 0.7559 - learning_rate: 0.0100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 409ms/step\n",
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 1/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 105ms/step - accuracy: 0.4357 - loss: 0.7372 - val_accuracy: 0.4909 - val_loss: 0.6899 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 2/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.5313 - loss: 0.6887 - val_accuracy: 0.5455 - val_loss: 0.6885 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 3/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.5863 - loss: 0.6830 - val_accuracy: 0.5455 - val_loss: 0.6876 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 4/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.5261 - loss: 0.6786 - val_accuracy: 0.6182 - val_loss: 0.6823 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 5/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6786 - loss: 0.6562 - val_accuracy: 0.5455 - val_loss: 0.6638 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 6/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.6830 - loss: 0.6166 - val_accuracy: 0.6000 - val_loss: 0.6652 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 7/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6383 - loss: 0.6478 - val_accuracy: 0.6545 - val_loss: 0.6555 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 8/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.6997 - loss: 0.5801 - val_accuracy: 0.6364 - val_loss: 0.6740 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 9/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - accuracy: 0.6857 - loss: 0.6007 - val_accuracy: 0.6364 - val_loss: 0.6364 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 10/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - accuracy: 0.7429 - loss: 0.5475 - val_accuracy: 0.6182 - val_loss: 0.6341 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 11: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 11/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - accuracy: 0.7536 - loss: 0.5145 - val_accuracy: 0.7455 - val_loss: 0.6039 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 12: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 12/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.8157 - loss: 0.4186 - val_accuracy: 0.6364 - val_loss: 0.8081 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 13: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 13/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.8220 - loss: 0.4450 - val_accuracy: 0.7091 - val_loss: 0.6228 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 14: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 14/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.8475 - loss: 0.4282 - val_accuracy: 0.6364 - val_loss: 0.7319 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 15: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 15/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.7244 - loss: 0.5199 - val_accuracy: 0.5818 - val_loss: 0.7447 - learning_rate: 0.0100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 408ms/step\n",
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 1/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 127ms/step - accuracy: 0.5705 - loss: 0.7001 - val_accuracy: 0.4545 - val_loss: 0.6923 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 2/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - accuracy: 0.5781 - loss: 0.6799 - val_accuracy: 0.5455 - val_loss: 0.6959 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 3/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.6829 - loss: 0.6539 - val_accuracy: 0.5091 - val_loss: 0.7304 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 4/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - accuracy: 0.7074 - loss: 0.6107 - val_accuracy: 0.5091 - val_loss: 0.7685 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 5/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - accuracy: 0.7409 - loss: 0.5931 - val_accuracy: 0.4909 - val_loss: 0.8297 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 6/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.7553 - loss: 0.5124 - val_accuracy: 0.5818 - val_loss: 0.8948 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 7/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.7785 - loss: 0.4873 - val_accuracy: 0.5455 - val_loss: 0.8818 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 8/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.8320 - loss: 0.4600 - val_accuracy: 0.4909 - val_loss: 0.7930 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 9/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.8206 - loss: 0.4146 - val_accuracy: 0.5273 - val_loss: 0.9122 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 10/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.8444 - loss: 0.3991 - val_accuracy: 0.5273 - val_loss: 0.9179 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 11: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 11/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.8863 - loss: 0.3426 - val_accuracy: 0.5091 - val_loss: 0.9721 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 12: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 12/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.8398 - loss: 0.4071 - val_accuracy: 0.5818 - val_loss: 0.8911 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 13: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 13/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.8650 - loss: 0.3986 - val_accuracy: 0.5636 - val_loss: 1.0034 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 14: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 14/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - accuracy: 0.9160 - loss: 0.3154 - val_accuracy: 0.6000 - val_loss: 0.9813 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 15: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 15/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.8266 - loss: 0.4133 - val_accuracy: 0.5455 - val_loss: 1.0775 - learning_rate: 0.0100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 414ms/step\n",
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 1/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 122ms/step - accuracy: 0.5420 - loss: 0.7081 - val_accuracy: 0.5273 - val_loss: 0.6836 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 2/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 105ms/step - accuracy: 0.5104 - loss: 0.7191 - val_accuracy: 0.5818 - val_loss: 0.6804 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 3/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.5290 - loss: 0.6923 - val_accuracy: 0.5818 - val_loss: 0.6785 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 4/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.5376 - loss: 0.6682 - val_accuracy: 0.6545 - val_loss: 0.6443 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 5/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.6578 - loss: 0.6182 - val_accuracy: 0.6545 - val_loss: 0.6233 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 6/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.6864 - loss: 0.6137 - val_accuracy: 0.7091 - val_loss: 0.6178 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 7/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.7037 - loss: 0.5851 - val_accuracy: 0.7091 - val_loss: 0.5678 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 8/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.7733 - loss: 0.5537 - val_accuracy: 0.7455 - val_loss: 0.5795 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 9/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.7360 - loss: 0.5862 - val_accuracy: 0.6364 - val_loss: 0.5931 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 10/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - accuracy: 0.7720 - loss: 0.5077 - val_accuracy: 0.7273 - val_loss: 0.5728 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 11: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 11/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.7703 - loss: 0.4922 - val_accuracy: 0.6909 - val_loss: 0.6028 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 12: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 12/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 109ms/step - accuracy: 0.8335 - loss: 0.3906 - val_accuracy: 0.7273 - val_loss: 0.5954 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 13: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 13/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.8143 - loss: 0.4720 - val_accuracy: 0.7091 - val_loss: 0.6129 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 14: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 14/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.8301 - loss: 0.4103 - val_accuracy: 0.6727 - val_loss: 0.5873 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 15: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 15/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.7755 - loss: 0.4865 - val_accuracy: 0.7091 - val_loss: 0.6256 - learning_rate: 0.0100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 427ms/step\n",
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 1/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 123ms/step - accuracy: 0.5046 - loss: 0.7503 - val_accuracy: 0.5273 - val_loss: 0.6997 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 2/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - accuracy: 0.5525 - loss: 0.7081 - val_accuracy: 0.5636 - val_loss: 0.6923 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 3/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.5105 - loss: 0.6996 - val_accuracy: 0.4727 - val_loss: 0.6969 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 4/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.5656 - loss: 0.6734 - val_accuracy: 0.6000 - val_loss: 0.6838 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 5/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.6208 - loss: 0.6568 - val_accuracy: 0.6364 - val_loss: 0.6783 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 6/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.6276 - loss: 0.6496 - val_accuracy: 0.5636 - val_loss: 0.6746 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 7/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.6154 - loss: 0.6470 - val_accuracy: 0.5455 - val_loss: 0.6630 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 8/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.7724 - loss: 0.5729 - val_accuracy: 0.6364 - val_loss: 0.6602 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 9/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - accuracy: 0.7118 - loss: 0.5581 - val_accuracy: 0.6182 - val_loss: 0.6705 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 10/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - accuracy: 0.6302 - loss: 0.6289 - val_accuracy: 0.4727 - val_loss: 0.6902 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 11: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 11/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.7425 - loss: 0.5643 - val_accuracy: 0.6182 - val_loss: 0.6423 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 12: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 12/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.7396 - loss: 0.5452 - val_accuracy: 0.5818 - val_loss: 0.6949 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 13: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 13/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.7706 - loss: 0.5266 - val_accuracy: 0.5818 - val_loss: 0.7244 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 14: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 14/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.7659 - loss: 0.4800 - val_accuracy: 0.5818 - val_loss: 0.6931 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 15: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 15/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.7385 - loss: 0.4902 - val_accuracy: 0.5455 - val_loss: 0.7832 - learning_rate: 0.0100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 408ms/step\n",
            "\n",
            "=== Deep Learning on Depression_Label ===\n",
            "(275, 87, 40)\n",
            "(275, 87, 40)\n",
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 1/15\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 90ms/step - accuracy: 0.5220 - loss: 0.7646 - val_accuracy: 0.7636 - val_loss: 0.6283 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 2/15\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.5295 - loss: 0.7020 - val_accuracy: 0.7818 - val_loss: 0.5970 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 3/15\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6740 - loss: 0.6269 - val_accuracy: 0.7455 - val_loss: 0.5868 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 4/15\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.6785 - loss: 0.6068 - val_accuracy: 0.7818 - val_loss: 0.4891 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 5/15\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.7118 - loss: 0.5342 - val_accuracy: 0.7818 - val_loss: 0.4978 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 6/15\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - accuracy: 0.7269 - loss: 0.5169 - val_accuracy: 0.7091 - val_loss: 0.5376 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 7/15\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - accuracy: 0.8022 - loss: 0.4581 - val_accuracy: 0.6545 - val_loss: 0.5416 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 8/15\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.8348 - loss: 0.3923 - val_accuracy: 0.6727 - val_loss: 0.5900 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 9/15\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.8566 - loss: 0.3608 - val_accuracy: 0.7273 - val_loss: 0.6021 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 10/15\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 61ms/step - accuracy: 0.8457 - loss: 0.3604 - val_accuracy: 0.6909 - val_loss: 0.6146 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 11: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 11/15\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.8858 - loss: 0.3138 - val_accuracy: 0.6545 - val_loss: 0.6430 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 12: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 12/15\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.8609 - loss: 0.3112 - val_accuracy: 0.7091 - val_loss: 0.6901 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 13: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 13/15\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9098 - loss: 0.2464 - val_accuracy: 0.6182 - val_loss: 0.7301 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 14: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 14/15\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - accuracy: 0.8933 - loss: 0.2445 - val_accuracy: 0.6182 - val_loss: 0.7937 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 15: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 15/15\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.8755 - loss: 0.2674 - val_accuracy: 0.6909 - val_loss: 0.6947 - learning_rate: 0.0100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 388ms/step\n",
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 1/15\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 129ms/step - accuracy: 0.4767 - loss: 0.7766 - val_accuracy: 0.6909 - val_loss: 0.6601 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 2/15\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.5360 - loss: 0.6942 - val_accuracy: 0.4545 - val_loss: 0.6942 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 3/15\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 62ms/step - accuracy: 0.6087 - loss: 0.6604 - val_accuracy: 0.7636 - val_loss: 0.5672 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 4/15\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6372 - loss: 0.6202 - val_accuracy: 0.7273 - val_loss: 0.5090 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 5/15\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7618 - loss: 0.5096 - val_accuracy: 0.6909 - val_loss: 0.5124 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 6/15\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.8170 - loss: 0.4254 - val_accuracy: 0.7091 - val_loss: 0.5705 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 7/15\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.8567 - loss: 0.3941 - val_accuracy: 0.7273 - val_loss: 0.5351 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 8/15\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 93ms/step - accuracy: 0.8525 - loss: 0.3425 - val_accuracy: 0.6182 - val_loss: 0.7464 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 9/15\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 0.8732 - loss: 0.3211 - val_accuracy: 0.7273 - val_loss: 0.8105 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 10/15\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step - accuracy: 0.9001 - loss: 0.2675 - val_accuracy: 0.7091 - val_loss: 0.6093 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 11: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 11/15\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 61ms/step - accuracy: 0.9291 - loss: 0.2026 - val_accuracy: 0.7455 - val_loss: 0.5991 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 12: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 12/15\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.8738 - loss: 0.2988 - val_accuracy: 0.7091 - val_loss: 0.7866 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 13: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 13/15\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - accuracy: 0.9102 - loss: 0.2296 - val_accuracy: 0.7636 - val_loss: 0.8034 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 14: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 14/15\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.9202 - loss: 0.2028 - val_accuracy: 0.7273 - val_loss: 0.8296 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 15: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 15/15\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.9156 - loss: 0.2499 - val_accuracy: 0.6727 - val_loss: 0.8586 - learning_rate: 0.0100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 406ms/step\n",
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 1/15\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 138ms/step - accuracy: 0.5061 - loss: 0.8283 - val_accuracy: 0.7273 - val_loss: 0.6531 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 2/15\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.5791 - loss: 0.6759 - val_accuracy: 0.5455 - val_loss: 0.6706 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 3/15\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - accuracy: 0.6454 - loss: 0.6467 - val_accuracy: 0.5091 - val_loss: 0.6950 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 4/15\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 62ms/step - accuracy: 0.6305 - loss: 0.6317 - val_accuracy: 0.5273 - val_loss: 0.6817 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 5/15\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - accuracy: 0.7234 - loss: 0.5548 - val_accuracy: 0.6000 - val_loss: 0.6576 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 6/15\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - accuracy: 0.7584 - loss: 0.5354 - val_accuracy: 0.6182 - val_loss: 0.7319 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 7/15\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 0.8611 - loss: 0.4133 - val_accuracy: 0.6364 - val_loss: 0.8152 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 8/15\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.8241 - loss: 0.3728 - val_accuracy: 0.5455 - val_loss: 0.9174 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 9/15\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - accuracy: 0.8636 - loss: 0.3733 - val_accuracy: 0.5273 - val_loss: 0.9516 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 10/15\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.8804 - loss: 0.3534 - val_accuracy: 0.6000 - val_loss: 0.9803 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 11: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 11/15\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.8819 - loss: 0.2862 - val_accuracy: 0.6182 - val_loss: 0.9046 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 12: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 12/15\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 61ms/step - accuracy: 0.9295 - loss: 0.2636 - val_accuracy: 0.6000 - val_loss: 0.9867 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 13: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 13/15\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - accuracy: 0.9007 - loss: 0.2900 - val_accuracy: 0.6000 - val_loss: 0.9087 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 14: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 14/15\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 0.9046 - loss: 0.2520 - val_accuracy: 0.6182 - val_loss: 0.9558 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 15: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 15/15\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.9019 - loss: 0.2572 - val_accuracy: 0.6364 - val_loss: 0.8194 - learning_rate: 0.0100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 391ms/step\n",
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 1/15\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 133ms/step - accuracy: 0.5127 - loss: 0.7049 - val_accuracy: 0.6727 - val_loss: 0.6860 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 2/15\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 76ms/step - accuracy: 0.5458 - loss: 0.6872 - val_accuracy: 0.4364 - val_loss: 0.6946 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 3/15\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6895 - loss: 0.6403 - val_accuracy: 0.4727 - val_loss: 0.7302 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 4/15\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.8080 - loss: 0.5127 - val_accuracy: 0.5455 - val_loss: 0.8290 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 5/15\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7991 - loss: 0.4329 - val_accuracy: 0.5636 - val_loss: 0.8561 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 6/15\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 61ms/step - accuracy: 0.8245 - loss: 0.4251 - val_accuracy: 0.6000 - val_loss: 0.8177 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 7/15\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.9081 - loss: 0.2899 - val_accuracy: 0.6000 - val_loss: 0.9030 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 8/15\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.9151 - loss: 0.2521 - val_accuracy: 0.6909 - val_loss: 0.9047 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 9/15\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.9234 - loss: 0.2297 - val_accuracy: 0.6364 - val_loss: 1.0057 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 10/15\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.9288 - loss: 0.1801 - val_accuracy: 0.5818 - val_loss: 1.1064 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 11: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 11/15\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.9241 - loss: 0.2601 - val_accuracy: 0.5818 - val_loss: 1.0242 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 12: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 12/15\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.9617 - loss: 0.1558 - val_accuracy: 0.6364 - val_loss: 1.0068 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 13: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 13/15\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 62ms/step - accuracy: 0.9418 - loss: 0.1710 - val_accuracy: 0.7091 - val_loss: 1.0574 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 14: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 14/15\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.9313 - loss: 0.1582 - val_accuracy: 0.6545 - val_loss: 1.1884 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 15: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 15/15\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.9563 - loss: 0.1455 - val_accuracy: 0.6545 - val_loss: 1.2641 - learning_rate: 0.0100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 558ms/step\n",
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 1/15\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 76ms/step - accuracy: 0.5378 - loss: 0.6883 - val_accuracy: 0.6727 - val_loss: 0.6726 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 2/15\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 0.5347 - loss: 0.6710 - val_accuracy: 0.7273 - val_loss: 0.5763 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 3/15\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.6010 - loss: 0.6528 - val_accuracy: 0.6727 - val_loss: 0.6074 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 4/15\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - accuracy: 0.7466 - loss: 0.5518 - val_accuracy: 0.6000 - val_loss: 0.6376 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 5/15\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.8290 - loss: 0.4537 - val_accuracy: 0.6727 - val_loss: 0.6745 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 6/15\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 0.8333 - loss: 0.4078 - val_accuracy: 0.6545 - val_loss: 0.8310 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 7/15\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.8622 - loss: 0.3511 - val_accuracy: 0.6182 - val_loss: 0.8302 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 8/15\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.8664 - loss: 0.3600 - val_accuracy: 0.5273 - val_loss: 1.1652 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 9/15\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.8749 - loss: 0.3225 - val_accuracy: 0.4727 - val_loss: 1.4051 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 10/15\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.8527 - loss: 0.3899 - val_accuracy: 0.5455 - val_loss: 1.1337 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 11: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 11/15\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9052 - loss: 0.2167 - val_accuracy: 0.6182 - val_loss: 1.1601 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 12: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 12/15\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9251 - loss: 0.2514 - val_accuracy: 0.6000 - val_loss: 1.1670 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 13: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 13/15\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9612 - loss: 0.1703 - val_accuracy: 0.6364 - val_loss: 1.1062 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 14: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 14/15\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - accuracy: 0.8979 - loss: 0.2712 - val_accuracy: 0.5818 - val_loss: 1.3139 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 15: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 15/15\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 0.9275 - loss: 0.1734 - val_accuracy: 0.5818 - val_loss: 1.3426 - learning_rate: 0.0100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 411ms/step\n",
            "\n",
            "=== Deep Learning on PTSD_Label ===\n",
            "(275, 87, 40)\n",
            "(275, 87, 40)\n",
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 1/15\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 121ms/step - accuracy: 0.4379 - loss: 0.8254 - val_accuracy: 0.3091 - val_loss: 0.7283 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 2/15\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - accuracy: 0.5929 - loss: 0.6787 - val_accuracy: 0.3091 - val_loss: 0.7944 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 3/15\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - accuracy: 0.6457 - loss: 0.6444 - val_accuracy: 0.5455 - val_loss: 0.6973 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 4/15\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.8019 - loss: 0.5208 - val_accuracy: 0.4727 - val_loss: 0.8637 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 5/15\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.7811 - loss: 0.4980 - val_accuracy: 0.6000 - val_loss: 0.7295 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 6/15\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.8459 - loss: 0.4031 - val_accuracy: 0.6545 - val_loss: 0.6874 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 7/15\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.8097 - loss: 0.4344 - val_accuracy: 0.6727 - val_loss: 0.7626 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 8/15\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.8804 - loss: 0.3009 - val_accuracy: 0.8000 - val_loss: 0.5253 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 9/15\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.8267 - loss: 0.3734 - val_accuracy: 0.7455 - val_loss: 0.5355 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 10/15\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.8677 - loss: 0.3317 - val_accuracy: 0.7636 - val_loss: 0.5215 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 11: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 11/15\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 0.9045 - loss: 0.2374 - val_accuracy: 0.7455 - val_loss: 0.5122 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 12: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 12/15\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.9174 - loss: 0.2404 - val_accuracy: 0.7818 - val_loss: 0.5054 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 13: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 13/15\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.9384 - loss: 0.1861 - val_accuracy: 0.8182 - val_loss: 0.4934 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 14: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 14/15\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.9271 - loss: 0.1904 - val_accuracy: 0.8000 - val_loss: 0.5783 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 15: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 15/15\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.9123 - loss: 0.2318 - val_accuracy: 0.7273 - val_loss: 0.6401 - learning_rate: 0.0100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 426ms/step\n",
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 1/15\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 96ms/step - accuracy: 0.4788 - loss: 0.8167 - val_accuracy: 0.5455 - val_loss: 0.6857 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 2/15\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - accuracy: 0.6333 - loss: 0.6348 - val_accuracy: 0.5818 - val_loss: 0.6969 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 3/15\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - accuracy: 0.7460 - loss: 0.5750 - val_accuracy: 0.6545 - val_loss: 0.6559 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 4/15\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.7770 - loss: 0.5449 - val_accuracy: 0.6182 - val_loss: 0.6616 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 5/15\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - accuracy: 0.7843 - loss: 0.5122 - val_accuracy: 0.7091 - val_loss: 0.5811 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 6/15\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - accuracy: 0.8290 - loss: 0.4355 - val_accuracy: 0.7818 - val_loss: 0.6028 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 7/15\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.8470 - loss: 0.3747 - val_accuracy: 0.7636 - val_loss: 0.5767 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 8/15\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.8622 - loss: 0.3559 - val_accuracy: 0.7636 - val_loss: 0.6408 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 9/15\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.8507 - loss: 0.3612 - val_accuracy: 0.7091 - val_loss: 0.6773 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 10/15\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.8933 - loss: 0.3041 - val_accuracy: 0.7818 - val_loss: 0.5984 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 11: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 11/15\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 66ms/step - accuracy: 0.8791 - loss: 0.3256 - val_accuracy: 0.7818 - val_loss: 0.6412 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 12: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 12/15\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 71ms/step - accuracy: 0.9085 - loss: 0.3143 - val_accuracy: 0.8000 - val_loss: 0.6538 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 13: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 13/15\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 86ms/step - accuracy: 0.8908 - loss: 0.2758 - val_accuracy: 0.6909 - val_loss: 0.7024 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 14: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 14/15\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - accuracy: 0.8975 - loss: 0.2793 - val_accuracy: 0.7636 - val_loss: 0.7792 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 15: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 15/15\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.8699 - loss: 0.3406 - val_accuracy: 0.7818 - val_loss: 0.6772 - learning_rate: 0.0100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 403ms/step\n",
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 1/15\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 96ms/step - accuracy: 0.4732 - loss: 0.7576 - val_accuracy: 0.6727 - val_loss: 0.6110 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 2/15\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - accuracy: 0.6644 - loss: 0.6290 - val_accuracy: 0.6182 - val_loss: 0.5681 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 3/15\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.7826 - loss: 0.5298 - val_accuracy: 0.6727 - val_loss: 0.5893 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 4/15\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.7985 - loss: 0.4937 - val_accuracy: 0.6727 - val_loss: 0.6027 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 5/15\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.8468 - loss: 0.4132 - val_accuracy: 0.6364 - val_loss: 0.7513 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 6/15\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - accuracy: 0.8650 - loss: 0.3497 - val_accuracy: 0.6545 - val_loss: 0.7600 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 7/15\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - accuracy: 0.8803 - loss: 0.3260 - val_accuracy: 0.7091 - val_loss: 0.6939 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 8/15\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - accuracy: 0.8886 - loss: 0.3189 - val_accuracy: 0.6545 - val_loss: 0.7933 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 9/15\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.8968 - loss: 0.2926 - val_accuracy: 0.6909 - val_loss: 0.7909 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 10/15\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.9280 - loss: 0.3170 - val_accuracy: 0.6364 - val_loss: 0.7806 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 11: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 11/15\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.9183 - loss: 0.2420 - val_accuracy: 0.6545 - val_loss: 0.8216 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 12: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 12/15\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 64ms/step - accuracy: 0.9192 - loss: 0.2407 - val_accuracy: 0.6727 - val_loss: 0.8054 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 13: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 13/15\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.9121 - loss: 0.2462 - val_accuracy: 0.6545 - val_loss: 0.8583 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 14: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 14/15\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.9210 - loss: 0.2309 - val_accuracy: 0.6000 - val_loss: 0.8937 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 15: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 15/15\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - accuracy: 0.8606 - loss: 0.3273 - val_accuracy: 0.6545 - val_loss: 0.9395 - learning_rate: 0.0100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 407ms/step\n",
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 1/15\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 101ms/step - accuracy: 0.4614 - loss: 0.7092 - val_accuracy: 0.6364 - val_loss: 0.6879 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 2/15\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - accuracy: 0.4800 - loss: 0.6931 - val_accuracy: 0.6909 - val_loss: 0.6818 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 3/15\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - accuracy: 0.5306 - loss: 0.6882 - val_accuracy: 0.6727 - val_loss: 0.6650 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 4/15\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 66ms/step - accuracy: 0.6153 - loss: 0.6685 - val_accuracy: 0.7636 - val_loss: 0.6167 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 5/15\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.6981 - loss: 0.6023 - val_accuracy: 0.5818 - val_loss: 0.6408 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 6/15\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 65ms/step - accuracy: 0.6482 - loss: 0.6007 - val_accuracy: 0.6909 - val_loss: 0.5854 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 7/15\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.8034 - loss: 0.4915 - val_accuracy: 0.7636 - val_loss: 0.5398 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 8/15\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.8498 - loss: 0.4116 - val_accuracy: 0.7091 - val_loss: 0.6680 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 9/15\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - accuracy: 0.8331 - loss: 0.4014 - val_accuracy: 0.6545 - val_loss: 0.6366 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 10/15\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - accuracy: 0.8374 - loss: 0.3932 - val_accuracy: 0.7091 - val_loss: 0.7341 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 11: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 11/15\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.8854 - loss: 0.3305 - val_accuracy: 0.7455 - val_loss: 0.6761 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 12: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 12/15\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.8736 - loss: 0.3363 - val_accuracy: 0.6364 - val_loss: 0.9622 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 13: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 13/15\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 65ms/step - accuracy: 0.8963 - loss: 0.2871 - val_accuracy: 0.6364 - val_loss: 0.9736 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 14: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 14/15\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.8871 - loss: 0.3163 - val_accuracy: 0.7273 - val_loss: 0.7155 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 15: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 15/15\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 67ms/step - accuracy: 0.9280 - loss: 0.2787 - val_accuracy: 0.7273 - val_loss: 0.7617 - learning_rate: 0.0100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4s/step\n",
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 1/15\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 146ms/step - accuracy: 0.5406 - loss: 0.7441 - val_accuracy: 0.3455 - val_loss: 0.7501 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 2/15\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - accuracy: 0.5815 - loss: 0.6693 - val_accuracy: 0.6727 - val_loss: 0.6556 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 3/15\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 0.7036 - loss: 0.6214 - val_accuracy: 0.7091 - val_loss: 0.6366 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 4/15\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.7010 - loss: 0.5967 - val_accuracy: 0.6909 - val_loss: 0.6453 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 5/15\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.7383 - loss: 0.5372 - val_accuracy: 0.5636 - val_loss: 0.7572 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 6/15\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.8387 - loss: 0.4384 - val_accuracy: 0.5636 - val_loss: 0.7397 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 7/15\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 73ms/step - accuracy: 0.8463 - loss: 0.4127 - val_accuracy: 0.7091 - val_loss: 0.6014 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 8/15\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - accuracy: 0.8349 - loss: 0.3880 - val_accuracy: 0.7273 - val_loss: 0.5852 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 9/15\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 86ms/step - accuracy: 0.8588 - loss: 0.3365 - val_accuracy: 0.6727 - val_loss: 0.6703 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 10/15\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 76ms/step - accuracy: 0.8631 - loss: 0.3141 - val_accuracy: 0.6545 - val_loss: 0.7042 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 11: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 11/15\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.8850 - loss: 0.3321 - val_accuracy: 0.6727 - val_loss: 0.6483 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 12: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 12/15\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.8667 - loss: 0.3227 - val_accuracy: 0.7273 - val_loss: 0.6319 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 13: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 13/15\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.8887 - loss: 0.2650 - val_accuracy: 0.7273 - val_loss: 0.7018 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 14: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 14/15\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.9119 - loss: 0.2603 - val_accuracy: 0.7636 - val_loss: 0.7489 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 15: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 15/15\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 103ms/step - accuracy: 0.8941 - loss: 0.2523 - val_accuracy: 0.7091 - val_loss: 0.7442 - learning_rate: 0.0100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 482ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "# Function to compute metrics\n",
        "def compute_metrics_dl(y_true, y_pred):\n",
        "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "    acc = (tp + tn) / (tp + tn + fp + fn)\n",
        "    sens = tp / (tp + fn) if (tp + fn) else 0\n",
        "    spec = tn / (tn + fp) if (tn + fp) else 0\n",
        "    return acc, sens, spec  # keep raw (not rounded yet)\n",
        "\n",
        "# Store mean ± std dev metrics\n",
        "results_dl = {}\n",
        "\n",
        "df = pd.read_csv('/content/GroundTruth Table.csv')\n",
        "MAX_CHUNKS = 87\n",
        "labels = ['Appetite_Label', 'Anxiety_Label', 'Sleep_Label', 'Agency_Label', 'Depression_Label', 'PTSD_Label']\n",
        "\n",
        "for label in labels:\n",
        "    print(f\"\\n=== Deep Learning on {label} ===\")\n",
        "    X = summary_features.copy()\n",
        "    y = df[label]\n",
        "\n",
        "    discrete_features = [False] * X.shape[1]\n",
        "    mi_scores = make_mi_scores(X, y, discrete_features)\n",
        "    filtered_scores = mi_scores[mi_scores > 0]\n",
        "    filtered_X = X[filtered_scores.index]\n",
        "\n",
        "    # Drop highly correlated features\n",
        "    corr_matrix = filtered_X.corr().abs()\n",
        "    to_drop = {\n",
        "        col2 if filtered_scores[col1] >= filtered_scores[col2] else col1\n",
        "        for i, col1 in enumerate(corr_matrix.columns)\n",
        "        for j, col2 in enumerate(corr_matrix.columns)\n",
        "        if i < j and corr_matrix.loc[col1, col2] > 0.8\n",
        "    }\n",
        "\n",
        "    final_X = filtered_X.drop(columns=to_drop)\n",
        "    final_scores = filtered_scores.drop(labels=to_drop)\n",
        "\n",
        "    # Select top 20% features\n",
        "    top_features = final_scores.sort_values(ascending=False).head(int(len(final_scores) * 0.2))\n",
        "    top_features_list = top_features.index.tolist()\n",
        "\n",
        "    # Map feature names to All_features.csv naming\n",
        "    extracted_features = []\n",
        "    for feature in top_features_list:\n",
        "        match = re.match(r'^(MFCC|eGeMAPS|FAU)_f(\\d+)_((?:mean)|(?:std)|(?:min)|(?:max))$', feature)\n",
        "        if match:\n",
        "            category, number, _ = match.groups()\n",
        "            number = int(number)\n",
        "            if category == \"MFCC\":\n",
        "                mapped = f\"feature_{number-1}\"\n",
        "            elif category == \"eGeMAPS\":\n",
        "                mapped = f\"feature_{number + 99}\"\n",
        "            elif category == \"FAU\":\n",
        "                mapped = f\"feature_{number + 199}\"\n",
        "            extracted_features.append(mapped)\n",
        "\n",
        "    # Load extracted features\n",
        "    X_all_label = pd.read_csv('/content/All_features.csv', usecols=extracted_features)\n",
        "    y_all_label = df[label]\n",
        "\n",
        "    X_all_label = np.array(X_all_label).reshape(275, MAX_CHUNKS, -1)\n",
        "    X_all_label = X_all_label[:, :-1, :]\n",
        "    y_all_label = np.array(y_all_label)\n",
        "\n",
        "    # Store all metrics across 10 runs\n",
        "    all_runs_metrics = []\n",
        "\n",
        "    for run in range(10):\n",
        "        fold_metrics = []\n",
        "        kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42 + run)\n",
        "\n",
        "        for train_index, test_index in kf.split(X_all_label, y_all_label):\n",
        "            X_train, X_test = X_all_label[train_index], X_all_label[test_index]\n",
        "            y_train, y_test = y_all_label[train_index], y_all_label[test_index]\n",
        "\n",
        "            model = build_model(input_shape=(X_all_label.shape[1], X_all_label.shape[2]))\n",
        "            model.fit(X_train, y_train, batch_size=32, epochs=15, verbose=0)\n",
        "\n",
        "            y_pred_prob = model.predict(X_test)\n",
        "            y_pred = (y_pred_prob > 0.5).astype(int)\n",
        "\n",
        "            acc, sens, spec = compute_metrics_dl(y_test, y_pred)\n",
        "            fold_metrics.append((acc, sens, spec))\n",
        "\n",
        "        all_runs_metrics.append(np.mean(fold_metrics, axis=0))\n",
        "\n",
        "    all_runs_metrics = np.array(all_runs_metrics)\n",
        "    means = np.mean(all_runs_metrics, axis=0)\n",
        "    stds = np.std(all_runs_metrics, axis=0)\n",
        "\n",
        "    results_dl[label] = {\n",
        "        \"accuracy\": f\"{means[0]:.4f} ± {stds[0]:.4f}\",\n",
        "        \"sensitivity\": f\"{means[1]:.4f} ± {stds[1]:.4f}\",\n",
        "        \"specificity\": f\"{means[2]:.4f} ± {stds[2]:.4f}\"\n",
        "    }\n",
        "\n",
        "# Convert to DataFrame and save\n",
        "summary_df = pd.DataFrame(results_dl).T\n",
        "summary_df.index.name = \"Label\"\n",
        "\n",
        "print(\"\\n===== Final Deep Learning Metrics (10 runs, mean ± std) =====\")\n",
        "print(summary_df)\n",
        "\n",
        "summary_df.to_csv(\"dl_summary_metrics.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hneg4t-HrKp7",
        "outputId": "e6d9d7d5-5b77-4bae-9172-109d5d9e6595"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Deep Learning on Appetite_Label ===\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 672ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 597ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 653ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 490ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 433ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 664ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 674ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 443ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 490ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 490ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 471ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 437ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 447ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 401ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 455ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 447ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 422ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 700ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 451ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 420ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 424ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 476ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 440ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 429ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 433ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 501ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 443ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 453ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 440ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 798ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 671ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 437ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 468ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 477ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 439ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 661ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 435ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 426ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 442ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 452ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 439ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 459ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 462ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 482ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 674ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 672ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 430ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 425ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 411ms/step\n",
            "\n",
            "=== Deep Learning on Anxiety_Label ===\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 426ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 506ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 611ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 427ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 482ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 694ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 559ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 459ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 414ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 444ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 445ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 659ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 406ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 435ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 418ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 410ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 424ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 624ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 484ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 435ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 423ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 435ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 646ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 470ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 673ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 434ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 463ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 446ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 472ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 511ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 445ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 566ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 685ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 647ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 649ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 430ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 464ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 437ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 686ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 438ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 485ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 416ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 417ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 600ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 440ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 564ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 496ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 443ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 459ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 437ms/step\n",
            "\n",
            "=== Deep Learning on Sleep_Label ===\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 450ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 430ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 467ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 671ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 584ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 416ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 433ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 411ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 472ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 465ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 400ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 423ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 434ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 442ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 597ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 499ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 425ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 453ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 429ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 435ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 455ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 495ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 643ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 726ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 641ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 452ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 543ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 470ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 445ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 432ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 679ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 662ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 629ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 448ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 447ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 436ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 467ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 427ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 489ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 417ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 424ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 465ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 492ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 467ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 642ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 407ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 411ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 458ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 630ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 531ms/step\n",
            "\n",
            "=== Deep Learning on Agency_Label ===\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 410ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 435ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 413ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 424ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 495ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 474ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 497ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 462ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 449ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 455ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 474ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 444ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 434ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 451ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 461ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 435ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 429ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 430ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 655ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 416ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 411ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 428ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 455ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 438ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 428ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 682ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 444ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 428ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 461ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 427ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 435ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 471ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 452ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 408ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 423ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 480ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 620ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 421ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 434ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 458ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 408ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 706ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 509ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 488ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 486ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 456ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 455ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 502ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 452ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 483ms/step\n",
            "\n",
            "=== Deep Learning on Depression_Label ===\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 446ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 472ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 451ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 435ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 451ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 674ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 682ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 517ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 441ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 431ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 461ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 431ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 665ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 447ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 454ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 423ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 427ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 438ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 431ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 414ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 433ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 430ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 442ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 421ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 585ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 516ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 419ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 407ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 424ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 420ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 431ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 423ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 409ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 487ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 417ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 416ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 409ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 728ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 681ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 668ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 517ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 476ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 437ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 451ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 500ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 504ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 446ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 430ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 476ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 438ms/step\n",
            "\n",
            "=== Deep Learning on PTSD_Label ===\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 426ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 420ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 450ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 415ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 447ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 407ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 607ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 702ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 594ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 450ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 443ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 413ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 422ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 445ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create a DataFrame from the results dictionary\n",
        "dl_df = pd.DataFrame.from_dict(\n",
        "    results_dl,\n",
        "    orient='index',\n",
        "    columns=['Accuracy', 'Sensitivity', 'Specificity']\n",
        ")\n",
        "\n",
        "# Add model name as a column\n",
        "dl_df.insert(0, 'Model', 'Deep CNN-BiLSTM')\n",
        "\n",
        "# Reorder index (labels become columns)\n",
        "dl_df = dl_df.transpose()\n",
        "dl_df.columns = [f'{label}' for label in dl_df.columns]\n",
        "\n",
        "# Optional: flatten the multi-index style\n",
        "dl_df.reset_index(inplace=True)\n",
        "dl_df.rename(columns={'index': 'Metric'}, inplace=True)\n",
        "\n",
        "# Save to CSV\n",
        "dl_df.to_csv(\"deep_model_results.csv\", index=False)\n",
        "\n",
        "# Display it\n",
        "print(\"\\nSaved Deep Learning metrics to 'deep_model_results.csv':\\n\")\n",
        "print(dl_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-PgByT0jHw8",
        "outputId": "04a10ad2-3dd2-4761-a82a-29a053778456"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Saved Deep Learning metrics to 'deep_model_results.csv':\n",
            "\n",
            "        Metric   Appetite_Label    Anxiety_Label      Sleep_Label  \\\n",
            "0        Model  Deep CNN-BiLSTM  Deep CNN-BiLSTM  Deep CNN-BiLSTM   \n",
            "1     Accuracy           0.6582           0.6582           0.6182   \n",
            "2  Sensitivity             0.48            0.669           0.5632   \n",
            "3  Specificity           0.7267           0.6455           0.6467   \n",
            "\n",
            "      Agency_Label Depression_Label       PTSD_Label  \n",
            "0  Deep CNN-BiLSTM  Deep CNN-BiLSTM  Deep CNN-BiLSTM  \n",
            "1           0.6146           0.6473             0.72  \n",
            "2           0.6598           0.3791           0.4013  \n",
            "3           0.5693           0.7317           0.8669  \n"
          ]
        }
      ]
    }
  ]
}